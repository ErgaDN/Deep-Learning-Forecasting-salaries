{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:16:47.139192300Z",
     "start_time": "2024-02-26T15:15:28.817439300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "211/211 [==============================] - 10s 23ms/step - loss: 22627.5059 - val_loss: 19252.6074\n",
      "Epoch 2/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 17307.1797 - val_loss: 15737.2393\n",
      "Epoch 3/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 14297.7783 - val_loss: 13130.7598\n",
      "Epoch 4/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 11964.2314 - val_loss: 11043.6924\n",
      "Epoch 5/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 10092.5557 - val_loss: 9372.9678\n",
      "Epoch 6/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 8583.7734 - val_loss: 8026.9312\n",
      "Epoch 7/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 7375.5239 - val_loss: 6953.2622\n",
      "Epoch 8/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 6424.6445 - val_loss: 6117.3765\n",
      "Epoch 9/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5690.9590 - val_loss: 5480.9395\n",
      "Epoch 10/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5137.2773 - val_loss: 5006.8423\n",
      "Epoch 11/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 4729.2856 - val_loss: 4663.9624\n",
      "Epoch 12/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 4441.4570 - val_loss: 4424.4878\n",
      "Epoch 13/20\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 4245.4375 - val_loss: 4266.7295\n",
      "Epoch 14/20\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 4117.3779 - val_loss: 4166.0107\n",
      "Epoch 15/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4037.6172 - val_loss: 4104.9321\n",
      "Epoch 16/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3990.5081 - val_loss: 4069.4485\n",
      "Epoch 17/20\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3964.3074 - val_loss: 4052.2271\n",
      "Epoch 18/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3950.3708 - val_loss: 4031.3738\n",
      "Epoch 19/20\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3123.0942 - val_loss: 2258.9202\n",
      "Epoch 20/20\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 1965.5389 - val_loss: 1820.9453\n",
      "59/59 [==============================] - 3s 6ms/step\n",
      "Mean Squared Error: 1940.6839011141424\n",
      "Root Mean Squared Error: 44.05319399446699\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(columns=\"salary_in_usd\")  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mean Squared Error: 1940.6839011141424\n",
    "Root Mean Squared Error: 44.05319399446699"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b545449918267e7a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   work_year             job_title                    job_category  \\\n0       2023  Data DevOps Engineer                Data Engineering   \n1       2023        Data Architect  Data Architecture and Modeling   \n2       2023        Data Architect  Data Architecture and Modeling   \n3       2023        Data Scientist       Data Science and Research   \n4       2023        Data Scientist       Data Science and Research   \n\n  salary_currency  salary  salary_in_usd employee_residence experience_level  \\\n0             EUR   88000         95.012            Germany        Mid-level   \n1             USD  186000        186.000      United States           Senior   \n2             USD   81800         81.800      United States           Senior   \n3             USD  212000        212.000      United States           Senior   \n4             USD   93300         93.300      United States           Senior   \n\n  employment_type work_setting company_location company_size  \n0       Full-time       Hybrid          Germany            L  \n1       Full-time    In-person    United States            M  \n2       Full-time    In-person    United States            M  \n3       Full-time    In-person    United States            M  \n4       Full-time    In-person    United States            M  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>work_year</th>\n      <th>job_title</th>\n      <th>job_category</th>\n      <th>salary_currency</th>\n      <th>salary</th>\n      <th>salary_in_usd</th>\n      <th>employee_residence</th>\n      <th>experience_level</th>\n      <th>employment_type</th>\n      <th>work_setting</th>\n      <th>company_location</th>\n      <th>company_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023</td>\n      <td>Data DevOps Engineer</td>\n      <td>Data Engineering</td>\n      <td>EUR</td>\n      <td>88000</td>\n      <td>95.012</td>\n      <td>Germany</td>\n      <td>Mid-level</td>\n      <td>Full-time</td>\n      <td>Hybrid</td>\n      <td>Germany</td>\n      <td>L</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023</td>\n      <td>Data Architect</td>\n      <td>Data Architecture and Modeling</td>\n      <td>USD</td>\n      <td>186000</td>\n      <td>186.000</td>\n      <td>United States</td>\n      <td>Senior</td>\n      <td>Full-time</td>\n      <td>In-person</td>\n      <td>United States</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023</td>\n      <td>Data Architect</td>\n      <td>Data Architecture and Modeling</td>\n      <td>USD</td>\n      <td>81800</td>\n      <td>81.800</td>\n      <td>United States</td>\n      <td>Senior</td>\n      <td>Full-time</td>\n      <td>In-person</td>\n      <td>United States</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023</td>\n      <td>Data Scientist</td>\n      <td>Data Science and Research</td>\n      <td>USD</td>\n      <td>212000</td>\n      <td>212.000</td>\n      <td>United States</td>\n      <td>Senior</td>\n      <td>Full-time</td>\n      <td>In-person</td>\n      <td>United States</td>\n      <td>M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023</td>\n      <td>Data Scientist</td>\n      <td>Data Science and Research</td>\n      <td>USD</td>\n      <td>93300</td>\n      <td>93.300</td>\n      <td>United States</td>\n      <td>Senior</td>\n      <td>Full-time</td>\n      <td>In-person</td>\n      <td>United States</td>\n      <td>M</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:16:47.177569200Z",
     "start_time": "2024-02-26T15:16:47.133041600Z"
    }
   },
   "id": "9c6cc14ad212805e"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erga9\\AppData\\Local\\Temp\\ipykernel_4928\\27342718.py:31: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  X_train_text_seq = pad_sequences(X_train.select_dtypes(include=[np.object]).apply(lambda x: x.astype(str)), maxlen=max_sequence_length)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 31\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Preprocess text data\u001B[39;00m\n\u001B[0;32m     30\u001B[0m max_sequence_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m  \u001B[38;5;66;03m# Maximum sequence length for padding\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m X_train_text_seq \u001B[38;5;241m=\u001B[39m pad_sequences(X_train\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39m[\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobject\u001B[49m])\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)), maxlen\u001B[38;5;241m=\u001B[39mmax_sequence_length)\n\u001B[0;32m     32\u001B[0m X_test_text_seq \u001B[38;5;241m=\u001B[39m pad_sequences(X_test\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39mobject])\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)), maxlen\u001B[38;5;241m=\u001B[39mmax_sequence_length)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# Define the model architecture\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\__init__.py:338\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    333\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    334\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    335\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 338\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtesting\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtesting\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Drop the \"salary\" column\n",
    "df = df.drop(columns=[\"salary\"])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = df.drop(columns=[\"salary_in_usd\"])  # Features\n",
    "y = df[\"salary_in_usd\"]  # Target variable\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess numerical data\n",
    "scaler = StandardScaler()\n",
    "X_train_numerical_scaled = scaler.fit_transform(X_train.select_dtypes(include=np.number))\n",
    "X_test_numerical_scaled = scaler.transform(X_test.select_dtypes(include=np.number))\n",
    "\n",
    "# Preprocess text data\n",
    "max_sequence_length = 100  # Maximum sequence length for padding\n",
    "X_train_text_seq = pad_sequences(X_train.select_dtypes(include=[np.object]).apply(lambda x: x.astype(str)), maxlen=max_sequence_length)\n",
    "X_test_text_seq = pad_sequences(X_test.select_dtypes(include=[np.object]).apply(lambda x: x.astype(str)), maxlen=max_sequence_length)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=1000, output_dim=64, input_length=max_sequence_length),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "print(\"Model summary:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([X_train_text_seq, X_train_numerical_scaled], y_train, epochs=20, batch_size=64, validation_data=([X_test_text_seq, X_test_numerical_scaled], y_test), callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict([X_test_text_seq, X_test_numerical_scaled])\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mse))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T15:27:32.751074200Z",
     "start_time": "2024-02-26T15:27:32.665627600Z"
    }
   },
   "id": "40536bf48621ebc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4212d23db6073cac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:46:46.037436400Z",
     "start_time": "2024-02-27T16:46:45.198923800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.src.layers import LSTM, Dense\n",
    "from keras.src.layers import Dropout\n",
    "from keras import Model, Input\n",
    "from keras.src.optimizers import Adam\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:19:46.536701600Z",
     "start_time": "2024-02-27T11:14:06.816179800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 18s 30ms/step - loss: 23861.4863 - val_loss: 20065.5254\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 18148.7207 - val_loss: 16717.2148\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 15423.0566 - val_loss: 14384.2949\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 13312.9268 - val_loss: 12474.0977\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 11561.8047 - val_loss: 10871.6084\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 10086.5498 - val_loss: 9516.6992\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 8845.8984 - val_loss: 8385.4111\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 7804.8374 - val_loss: 7436.6997\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 6939.0742 - val_loss: 6651.1621\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 6227.4697 - val_loss: 6012.8086\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5650.2930 - val_loss: 5496.5952\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 5189.2852 - val_loss: 5088.1860\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4831.0459 - val_loss: 4774.7783\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4557.0889 - val_loss: 4541.4419\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4352.8872 - val_loss: 4367.2676\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4207.0078 - val_loss: 4245.6118\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4105.8145 - val_loss: 4162.6343\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4038.6838 - val_loss: 4109.4014\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3996.0601 - val_loss: 4076.5627\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3970.3616 - val_loss: 4057.2827\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3955.7324 - val_loss: 4046.6533\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3947.7446 - val_loss: 4040.0730\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 3885.0718 - val_loss: 3910.3584\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3847.4607 - val_loss: 3901.4607\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3841.1223 - val_loss: 3896.9084\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3839.8875 - val_loss: 3882.3101\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3834.0906 - val_loss: 3879.7693\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3832.1587 - val_loss: 3885.9565\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3828.1321 - val_loss: 3876.2881\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3826.8003 - val_loss: 3874.8530\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3834.0400 - val_loss: 3881.3025\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4275 - val_loss: 3874.5701\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3828.8333 - val_loss: 3883.4172\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3828.9521 - val_loss: 3875.2771\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.8091 - val_loss: 3881.0376\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3828.7134 - val_loss: 3878.0745\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3828.8618 - val_loss: 3877.0139\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3830.5435 - val_loss: 3877.8984\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3824.5266 - val_loss: 3873.6372\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3826.3015 - val_loss: 3874.1130\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3826.3689 - val_loss: 3873.2375\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.3245 - val_loss: 3876.3303\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3825.7876 - val_loss: 3877.4006\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.8186 - val_loss: 3874.2388\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.6316 - val_loss: 3875.1208\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.1267 - val_loss: 3877.9824\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.4417 - val_loss: 3877.7490\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.6016 - val_loss: 3876.9219\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3823.8713 - val_loss: 3875.6565\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0671 - val_loss: 3876.2239\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.1772 - val_loss: 3879.3879\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3826.2246 - val_loss: 3876.5994\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3822.5339 - val_loss: 3880.3865\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3824.9729 - val_loss: 3878.2310\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3825.0625 - val_loss: 3883.0701\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.3101 - val_loss: 3875.8472\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.5886 - val_loss: 3879.5574\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.8313 - val_loss: 3878.4673\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3826.1643 - val_loss: 3875.4465\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3823.9377 - val_loss: 3885.9363\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4246 - val_loss: 3876.5662\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3825.0757 - val_loss: 3876.7437\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.4565 - val_loss: 3875.3464\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3823.6675 - val_loss: 3877.6216\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.6140 - val_loss: 3877.2637\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.2769 - val_loss: 3876.0371\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.9812 - val_loss: 3875.5210\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3823.9133 - val_loss: 3876.7234\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3823.8547 - val_loss: 3878.5608\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.5671 - val_loss: 3875.5212\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3825.2776 - val_loss: 3875.6309\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3823.8298 - val_loss: 3875.5674\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.2075 - val_loss: 3877.0784\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0662 - val_loss: 3875.8242\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.0854 - val_loss: 3875.9763\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.6956 - val_loss: 3878.5144\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.3279 - val_loss: 3877.3184\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.3586 - val_loss: 3877.4592\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4353 - val_loss: 3877.4099\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.6301 - val_loss: 3878.7903\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.3999 - val_loss: 3879.8555\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8630 - val_loss: 3878.3064\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8503 - val_loss: 3876.9363\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.6611 - val_loss: 3878.5420\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0757 - val_loss: 3877.4863\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.9822 - val_loss: 3877.0630\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3824.2847 - val_loss: 3877.1230\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.5103 - val_loss: 3875.7539\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.0662 - val_loss: 3883.1084\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.3303 - val_loss: 3880.3589\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.8054 - val_loss: 3876.8938\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.5635 - val_loss: 3881.8538\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8892 - val_loss: 3879.8062\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.2041 - val_loss: 3876.9072\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.0247 - val_loss: 3878.0864\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3823.6084 - val_loss: 3878.2808\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8667 - val_loss: 3877.9888\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.5354 - val_loss: 3876.9771\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3821.7288 - val_loss: 3879.6726\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.1860 - val_loss: 3876.6028\n",
      "59/59 [==============================] - 5s 6ms/step\n",
      "Mean Squared Error: 4085.98140515532\n",
      "Root Mean Squared Error: 63.92168180793838\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545449918267e7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Mean Squared Error: 4084.3665521731436\n",
    "Root Mean Squared Error: 63.909049063283234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bffea0c4c40d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c168b4c71b26642c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:26:09.529018900Z",
     "start_time": "2024-02-27T11:19:46.554704100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 19s 30ms/step - loss: 22610.9805 - val_loss: 19545.8242\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 17630.6074 - val_loss: 16079.5811\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 14638.8467 - val_loss: 13463.6426\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 12284.7783 - val_loss: 11352.9814\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 10375.2920 - val_loss: 9635.1289\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 8828.1270 - val_loss: 8250.1982\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 7582.1943 - val_loss: 7140.2505\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 6595.2783 - val_loss: 6268.6548\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 5827.7852 - val_loss: 5599.9434\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 5244.1255 - val_loss: 5100.1445\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 4810.7319 - val_loss: 4731.8325\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4500.0112 - val_loss: 4473.6016\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 4286.1362 - val_loss: 4300.4780\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 4142.5884 - val_loss: 4185.8833\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 4052.9375 - val_loss: 4116.3208\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3999.8323 - val_loss: 4076.3035\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3970.0242 - val_loss: 4055.8064\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3954.1108 - val_loss: 4044.9666\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3904.0422 - val_loss: 3910.4749\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3846.6167 - val_loss: 3888.5029\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3822.8726 - val_loss: 3875.7903\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3810.5354 - val_loss: 3860.5298\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3797.3977 - val_loss: 3849.4619\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3790.9077 - val_loss: 3836.9346\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3779.5977 - val_loss: 3833.2429\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3776.8350 - val_loss: 3829.0452\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3771.4788 - val_loss: 3832.7090\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3768.1313 - val_loss: 3819.2783\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3755.6697 - val_loss: 3812.9482\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3745.0903 - val_loss: 3804.6538\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3733.0730 - val_loss: 3797.5244\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3730.2307 - val_loss: 3795.9480\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3720.4810 - val_loss: 3791.0547\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3716.2810 - val_loss: 3788.1628\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3716.1829 - val_loss: 3786.8489\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3711.8677 - val_loss: 3786.5203\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3709.4534 - val_loss: 3784.8625\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3712.2925 - val_loss: 3786.9956\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3709.6455 - val_loss: 3785.5991\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3709.2219 - val_loss: 3787.4312\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3708.2441 - val_loss: 3784.7751\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3706.2668 - val_loss: 3783.5898\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3702.4143 - val_loss: 3783.7261\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3704.4009 - val_loss: 3783.5591\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3702.2205 - val_loss: 3782.7170\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3700.9941 - val_loss: 3783.0415\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3700.1509 - val_loss: 3780.4180\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3697.0139 - val_loss: 3783.1035\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3697.8486 - val_loss: 3778.1829\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3687.0818 - val_loss: 3768.8853\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3674.4873 - val_loss: 3752.0229\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3663.7256 - val_loss: 3737.4036\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3647.0793 - val_loss: 3715.3782\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3618.2456 - val_loss: 3689.0974\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3583.5662 - val_loss: 3653.5881\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3563.3838 - val_loss: 3649.5046\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3553.7190 - val_loss: 3632.4697\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3540.6716 - val_loss: 3611.7627\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3517.0381 - val_loss: 3598.3137\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3508.2412 - val_loss: 3587.6907\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3492.6714 - val_loss: 3582.9771\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3478.2881 - val_loss: 3565.9875\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3465.7896 - val_loss: 3549.5603\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3456.5701 - val_loss: 3552.3584\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3452.6272 - val_loss: 3550.7612\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3452.0112 - val_loss: 3549.4253\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3449.4707 - val_loss: 3547.1646\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3448.3267 - val_loss: 3546.5376\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3445.8494 - val_loss: 3542.3235\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3446.2563 - val_loss: 3545.7463\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3444.6882 - val_loss: 3544.1489\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3444.7720 - val_loss: 3536.7776\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3440.9829 - val_loss: 3535.2637\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3433.8767 - val_loss: 3529.3071\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3430.7222 - val_loss: 3528.7300\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3429.9246 - val_loss: 3527.0754\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3429.2385 - val_loss: 3526.1809\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3427.1323 - val_loss: 3525.1675\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3431.8157 - val_loss: 3524.5916\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3427.6729 - val_loss: 3523.9407\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3426.7246 - val_loss: 3524.3352\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.9951 - val_loss: 3523.6885\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.7344 - val_loss: 3522.2429\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.4871 - val_loss: 3514.3193\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3423.2007 - val_loss: 3515.4207\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3419.7849 - val_loss: 3514.9656\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3417.3689 - val_loss: 3511.5088\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.4443 - val_loss: 3510.6833\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.7197 - val_loss: 3511.8320\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.2063 - val_loss: 3499.9824\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3415.4224 - val_loss: 3511.0354\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3413.8137 - val_loss: 3507.1670\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3413.3850 - val_loss: 3508.3218\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3412.7922 - val_loss: 3507.0444\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3411.7185 - val_loss: 3502.9880\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3408.2603 - val_loss: 3498.9900\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3407.2324 - val_loss: 3500.3154\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3407.7351 - val_loss: 3496.9302\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3405.5603 - val_loss: 3496.7400\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3405.0635 - val_loss: 3495.0344\n",
      "59/59 [==============================] - 2s 7ms/step\n",
      "RMSE: 60.797518835041835\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb27b357a0a0af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n",
    "RMSE: 60.78381977426994"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "experience_mapping for ['experience_level']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed465217996aeb0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 14s 29ms/step - loss: 22351.6348 - val_loss: 19712.3477\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 17930.6953 - val_loss: 16432.7637\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 14972.0225 - val_loss: 13767.4268\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 12557.3984 - val_loss: 11591.9756\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 10582.8506 - val_loss: 9813.1934\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 8975.1074 - val_loss: 8373.9229\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 7685.1714 - val_loss: 7223.0566\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 6663.7358 - val_loss: 6325.9531\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 5870.7251 - val_loss: 5632.1987\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 5267.9644 - val_loss: 5116.2061\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 4822.2969 - val_loss: 4738.8813\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4504.9482 - val_loss: 4475.7485\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4286.6465 - val_loss: 4297.8530\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 4142.3589 - val_loss: 4185.4512\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4052.1890 - val_loss: 4116.3042\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3998.6453 - val_loss: 4076.2983\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3968.6682 - val_loss: 4054.2366\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3945.6614 - val_loss: 4000.0139\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 4141.6411 - val_loss: 4108.7886\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3941.8108 - val_loss: 3534.5583\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3342.5930 - val_loss: 3370.2781\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3219.0601 - val_loss: 3305.7490\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3165.0923 - val_loss: 3263.0730\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 3126.7009 - val_loss: 3244.3845\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 3109.6702 - val_loss: 3229.9492\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3098.4148 - val_loss: 3217.9089\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3090.3162 - val_loss: 3217.7244\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 3085.2378 - val_loss: 3205.5754\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3088.0217 - val_loss: 3200.8279\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3080.6343 - val_loss: 3195.9343\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3070.5146 - val_loss: 3253.2417\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3084.1658 - val_loss: 3195.8047\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3068.5815 - val_loss: 3190.5139\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3068.2319 - val_loss: 3191.7493\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3074.5342 - val_loss: 3188.5503\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3066.3450 - val_loss: 3190.5444\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3070.5720 - val_loss: 3186.2483\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3070.3635 - val_loss: 3191.6489\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3068.4705 - val_loss: 3195.7666\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3064.9792 - val_loss: 3186.7197\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3061.1709 - val_loss: 3198.9609\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3060.8657 - val_loss: 3186.5571\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3061.5149 - val_loss: 3183.9456\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3057.8445 - val_loss: 3183.2629\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3057.7036 - val_loss: 3181.0930\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3056.6741 - val_loss: 3179.8552\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3055.9316 - val_loss: 3181.7085\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3053.3193 - val_loss: 3180.1919\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3047.4797 - val_loss: 3181.9490\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 3056.2661 - val_loss: 3187.3684\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 7s 34ms/step - loss: 3051.5625 - val_loss: 3182.5618\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3053.3525 - val_loss: 3179.6685\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3047.7881 - val_loss: 3181.9790\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3046.6150 - val_loss: 3180.9192\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3046.0579 - val_loss: 3180.4624\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3043.0059 - val_loss: 3176.8625\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3040.8828 - val_loss: 3186.5593\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3042.1931 - val_loss: 3178.4285\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3035.7544 - val_loss: 3178.2144\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3040.1995 - val_loss: 3176.3589\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3035.5432 - val_loss: 3178.0867\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3032.9473 - val_loss: 3185.0825\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3032.5789 - val_loss: 3177.6753\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3034.0859 - val_loss: 3178.9585\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3036.7563 - val_loss: 3179.8235\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3032.0010 - val_loss: 3187.1602\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3031.8408 - val_loss: 3177.3152\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3033.0293 - val_loss: 3177.2112\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3030.0066 - val_loss: 3177.0081\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3029.0764 - val_loss: 3177.7783\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3027.8171 - val_loss: 3176.6899\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 3029.5659 - val_loss: 3176.4307\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3025.0579 - val_loss: 3178.7561\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3026.4871 - val_loss: 3177.3547\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 3025.1777 - val_loss: 3176.0283\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 8s 35ms/step - loss: 3026.2229 - val_loss: 3174.6711\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3024.9978 - val_loss: 3175.3118\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 3022.4089 - val_loss: 3177.2883\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3022.6560 - val_loss: 3189.7944\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.9143 - val_loss: 3175.3044\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.3396 - val_loss: 3173.9946\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3026.9253 - val_loss: 3176.6106\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3023.0049 - val_loss: 3178.3164\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3023.4946 - val_loss: 3175.8706\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3020.9761 - val_loss: 3178.5720\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3023.0847 - val_loss: 3178.0151\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3016.9658 - val_loss: 3178.8557\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.4795 - val_loss: 3179.8066\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3020.3616 - val_loss: 3178.1692\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3018.8362 - val_loss: 3175.9065\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3020.5957 - val_loss: 3175.3743\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3022.7717 - val_loss: 3177.9973\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3018.4238 - val_loss: 3176.5073\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3018.5444 - val_loss: 3177.3538\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3021.2803 - val_loss: 3179.8037\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3020.4229 - val_loss: 3179.0063\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3018.3430 - val_loss: 3178.0164\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3017.2820 - val_loss: 3177.7717\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3016.6323 - val_loss: 3178.0701\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3017.3000 - val_loss: 3184.4165\n",
      "59/59 [==============================] - 5s 8ms/step\n",
      "RMSE: 57.5500774333776\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:34:14.295240400Z",
     "start_time": "2024-02-27T11:26:09.536579800Z"
    }
   },
   "id": "5655332e67e284ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "experience_mapping for ['experience_level']\n",
    "RMSE: 57.54844132269867"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34367b8406b19476"
  },
  {
   "cell_type": "markdown",
   "source": [
    "distance from  [\"employee_residence\"] - [\"company_location\"] "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102f827262b8454c"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 4s 11ms/step - loss: 16256.1494 - mse: 16256.1494 - val_loss: 9955.7607 - val_mse: 9955.7607\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7026.3799 - mse: 7026.3799 - val_loss: 5222.2876 - val_mse: 5222.2876\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 4467.0806 - mse: 4467.0806 - val_loss: 4188.1245 - val_mse: 4188.1245\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 3997.3284 - mse: 3997.3284 - val_loss: 4032.2065 - val_mse: 4032.2065\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 3859.8037 - mse: 3859.8037 - val_loss: 3895.7830 - val_mse: 3895.7830\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 3714.5867 - mse: 3714.5867 - val_loss: 2581.5972 - val_mse: 2581.5972\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1958.4340 - mse: 1958.4340 - val_loss: 1720.2968 - val_mse: 1720.2968\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1427.7726 - mse: 1427.7726 - val_loss: 1445.3937 - val_mse: 1445.3937\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1188.7640 - mse: 1188.7640 - val_loss: 1236.9943 - val_mse: 1236.9943\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1044.9861 - mse: 1044.9861 - val_loss: 1153.5101 - val_mse: 1153.5101\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 952.4045 - mse: 952.4045 - val_loss: 1031.7080 - val_mse: 1031.7080\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 905.7674 - mse: 905.7674 - val_loss: 957.6584 - val_mse: 957.6584\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 852.8837 - mse: 852.8837 - val_loss: 919.7014 - val_mse: 919.7014\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 812.9153 - mse: 812.9153 - val_loss: 928.7402 - val_mse: 928.7402\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 800.8813 - mse: 800.8813 - val_loss: 918.6611 - val_mse: 918.6611\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 777.7141 - mse: 777.7141 - val_loss: 845.9786 - val_mse: 845.9786\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 764.5424 - mse: 764.5424 - val_loss: 819.4028 - val_mse: 819.4028\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 740.1538 - mse: 740.1538 - val_loss: 794.6003 - val_mse: 794.6003\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 742.6032 - mse: 742.6032 - val_loss: 778.6373 - val_mse: 778.6373\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 736.4969 - mse: 736.4969 - val_loss: 763.4811 - val_mse: 763.4811\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 721.5717 - mse: 721.5717 - val_loss: 788.6368 - val_mse: 788.6368\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 729.9215 - mse: 729.9215 - val_loss: 797.2829 - val_mse: 797.2829\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 713.1915 - mse: 713.1915 - val_loss: 823.2212 - val_mse: 823.2212\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 710.4378 - mse: 710.4378 - val_loss: 775.6736 - val_mse: 775.6736\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 708.1943 - mse: 708.1943 - val_loss: 808.6544 - val_mse: 808.6544\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 701.9424 - mse: 701.9424 - val_loss: 761.5634 - val_mse: 761.5634\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 686.2878 - mse: 686.2878 - val_loss: 759.2191 - val_mse: 759.2191\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 702.0068 - mse: 702.0068 - val_loss: 751.9566 - val_mse: 751.9566\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 697.0330 - mse: 697.0330 - val_loss: 736.8743 - val_mse: 736.8743\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 692.9588 - mse: 692.9588 - val_loss: 721.8361 - val_mse: 721.8361\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 678.4939 - mse: 678.4939 - val_loss: 725.2092 - val_mse: 725.2092\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 687.8171 - mse: 687.8171 - val_loss: 711.5720 - val_mse: 711.5720\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 684.9930 - mse: 684.9930 - val_loss: 727.1157 - val_mse: 727.1157\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 676.7206 - mse: 676.7206 - val_loss: 714.0688 - val_mse: 714.0688\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 683.6851 - mse: 683.6851 - val_loss: 731.8651 - val_mse: 731.8651\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 684.2993 - mse: 684.2993 - val_loss: 722.8378 - val_mse: 722.8378\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 683.4365 - mse: 683.4365 - val_loss: 729.6480 - val_mse: 729.6480\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 668.8553 - mse: 668.8553 - val_loss: 746.9152 - val_mse: 746.9152\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 679.6367 - mse: 679.6367 - val_loss: 774.4261 - val_mse: 774.4261\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 675.5131 - mse: 675.5131 - val_loss: 708.3879 - val_mse: 708.3879\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 679.5470 - mse: 679.5470 - val_loss: 722.3484 - val_mse: 722.3484\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 670.0061 - mse: 670.0061 - val_loss: 723.7585 - val_mse: 723.7585\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 665.7436 - mse: 665.7436 - val_loss: 707.9625 - val_mse: 707.9625\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 660.7507 - mse: 660.7507 - val_loss: 679.4191 - val_mse: 679.4191\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 669.4787 - mse: 669.4787 - val_loss: 701.2291 - val_mse: 701.2291\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 677.7209 - mse: 677.7209 - val_loss: 724.0349 - val_mse: 724.0349\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 666.2715 - mse: 666.2715 - val_loss: 705.4446 - val_mse: 705.4446\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 657.8080 - mse: 657.8080 - val_loss: 698.0468 - val_mse: 698.0468\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 660.6588 - mse: 660.6588 - val_loss: 732.2602 - val_mse: 732.2602\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 665.7889 - mse: 665.7889 - val_loss: 724.0475 - val_mse: 724.0475\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 676.1990 - mse: 676.1990 - val_loss: 764.9627 - val_mse: 764.9627\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 662.6624 - mse: 662.6624 - val_loss: 718.0080 - val_mse: 718.0080\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 652.6068 - mse: 652.6068 - val_loss: 685.6319 - val_mse: 685.6319\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 644.5942 - mse: 644.5942 - val_loss: 690.0109 - val_mse: 690.0109\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 652.7979 - mse: 652.7979 - val_loss: 673.8480 - val_mse: 673.8480\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 661.3393 - mse: 661.3393 - val_loss: 695.7886 - val_mse: 695.7886\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 648.5267 - mse: 648.5267 - val_loss: 695.8074 - val_mse: 695.8074\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 640.7017 - mse: 640.7017 - val_loss: 734.0626 - val_mse: 734.0626\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 655.2315 - mse: 655.2315 - val_loss: 691.4240 - val_mse: 691.4240\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 647.2791 - mse: 647.2791 - val_loss: 724.5921 - val_mse: 724.5921\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 645.7338 - mse: 645.7338 - val_loss: 677.1713 - val_mse: 677.1713\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 651.7472 - mse: 651.7472 - val_loss: 718.3680 - val_mse: 718.3680\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 654.1200 - mse: 654.1200 - val_loss: 671.4023 - val_mse: 671.4023\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 656.6880 - mse: 656.6880 - val_loss: 723.2707 - val_mse: 723.2707\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 645.5552 - mse: 645.5552 - val_loss: 710.6523 - val_mse: 710.6523\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 658.2999 - mse: 658.2999 - val_loss: 721.8793 - val_mse: 721.8793\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 665.5829 - mse: 665.5829 - val_loss: 710.4109 - val_mse: 710.4109\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 659.1092 - mse: 659.1092 - val_loss: 693.9460 - val_mse: 693.9460\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 654.2512 - mse: 654.2512 - val_loss: 751.2383 - val_mse: 751.2383\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 651.1439 - mse: 651.1439 - val_loss: 708.2341 - val_mse: 708.2341\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 654.1081 - mse: 654.1081 - val_loss: 699.9861 - val_mse: 699.9861\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 641.5715 - mse: 641.5715 - val_loss: 718.1624 - val_mse: 718.1624\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 652.4704 - mse: 652.4704 - val_loss: 686.8388 - val_mse: 686.8388\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 647.1720 - mse: 647.1720 - val_loss: 746.3373 - val_mse: 746.3373\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 642.4713 - mse: 642.4713 - val_loss: 692.9583 - val_mse: 692.9583\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 655.9750 - mse: 655.9750 - val_loss: 716.5784 - val_mse: 716.5784\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 649.0150 - mse: 649.0150 - val_loss: 700.8203 - val_mse: 700.8203\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 668.0524 - mse: 668.0524 - val_loss: 674.3807 - val_mse: 674.3807\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 658.2429 - mse: 658.2429 - val_loss: 676.8604 - val_mse: 676.8604\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 648.6304 - mse: 648.6304 - val_loss: 674.1216 - val_mse: 674.1216\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 651.1553 - mse: 651.1553 - val_loss: 820.9963 - val_mse: 820.9963\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 657.4032 - mse: 657.4032 - val_loss: 669.2225 - val_mse: 669.2225\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 635.0690 - mse: 635.0690 - val_loss: 689.5715 - val_mse: 689.5715\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 646.1260 - mse: 646.1260 - val_loss: 684.5944 - val_mse: 684.5944\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 660.4458 - mse: 660.4458 - val_loss: 715.2441 - val_mse: 715.2441\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 637.9071 - mse: 637.9071 - val_loss: 715.4600 - val_mse: 715.4600\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 653.8152 - mse: 653.8152 - val_loss: 754.5521 - val_mse: 754.5521\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 649.8716 - mse: 649.8716 - val_loss: 707.4389 - val_mse: 707.4389\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 642.9078 - mse: 642.9078 - val_loss: 675.9390 - val_mse: 675.9390\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 645.6370 - mse: 645.6370 - val_loss: 685.4817 - val_mse: 685.4817\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 649.9272 - mse: 649.9272 - val_loss: 686.5020 - val_mse: 686.5020\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 641.4460 - mse: 641.4460 - val_loss: 680.2785 - val_mse: 680.2785\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 640.2671 - mse: 640.2671 - val_loss: 693.7166 - val_mse: 693.7166\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 636.2210 - mse: 636.2210 - val_loss: 686.4943 - val_mse: 686.4943\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 636.4305 - mse: 636.4305 - val_loss: 688.8022 - val_mse: 688.8022\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 640.8536 - mse: 640.8536 - val_loss: 688.4077 - val_mse: 688.4077\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 648.8668 - mse: 648.8668 - val_loss: 690.7119 - val_mse: 690.7119\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 643.6668 - mse: 643.6668 - val_loss: 688.6580 - val_mse: 688.6580\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 636.5330 - mse: 636.5330 - val_loss: 707.5110 - val_mse: 707.5110\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 637.6992 - mse: 637.6992 - val_loss: 711.6406 - val_mse: 711.6406\n",
      "59/59 [==============================] - 1s 2ms/step\n",
      "RMSE: 25.571405026123266\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "\n",
    "# Calculate the percentile rank of each salary within its job category\n",
    "df['Percentile'] = df.groupby('job_category')['salary'].rank(pct=True)\n",
    "\n",
    "# Normalize the percentile ranks to a scale of 0 to 1\n",
    "min_percentile = df['Percentile'].min()\n",
    "max_percentile = df['Percentile'].max()\n",
    "df['Normalized_Salary_within_Job_Category'] = (df['Percentile'] - min_percentile) / (max_percentile - min_percentile)\n",
    "\n",
    "# Drop the temporary 'Percentile' column if you don't need it anymore\n",
    "df.drop(columns=['Percentile'], inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:46:08.684594700Z",
     "start_time": "2024-02-27T16:44:54.687355Z"
    }
   },
   "id": "8365c9c64a0687ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalized Salary within Job Category\n",
    "RMSE: 24.779573173916585"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4821ba084594397"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9123463388562266\n",
      "Precision: 0.9227330779054917\n",
      "Recall: 0.9711021505376344\n",
      "RMSE: 25.571405026123266\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the scaled test set\n",
    "predictions_scaled = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predictions = predictions_scaled.flatten()\n",
    "\n",
    "# Define thresholds for classification\n",
    "threshold_positive = 100  # Define a suitable threshold based on your problem\n",
    "\n",
    "# Classify predictions into two categories based on the threshold\n",
    "y_test_class = (y_test >= threshold_positive)\n",
    "predictions_class = (predictions >= threshold_positive)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_class, predictions_class)\n",
    "\n",
    "# Calculate percentages\n",
    "total = np.sum(conf_matrix)\n",
    "percentages = (conf_matrix / total) * 100\n",
    "\n",
    "# Define labels for each cell with amount, percentage, and the type of classification\n",
    "labels = np.empty_like(conf_matrix, dtype=object)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        if i == 0 and j == 0:  # True Negative\n",
    "            labels[i, j] = f\"TN\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        elif i == 0 and j == 1:  # False Positive\n",
    "            labels[i, j] = f\"FP\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        elif i == 1 and j == 0:  # False Negative\n",
    "            labels[i, j] = f\"FN\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        else:  # True Positive\n",
    "            labels[i, j] = f\"TP\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "\n",
    "# Plot confusion matrix with labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test_class, predictions_class)\n",
    "precision = precision_score(y_test_class, predictions_class)\n",
    "recall = recall_score(y_test_class, predictions_class)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Calculate and print RMSE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"RMSE:\", np.sqrt(mse))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:46:50.663424100Z",
     "start_time": "2024-02-27T16:46:50.303541700Z"
    }
   },
   "id": "b661a6f2fe28e110"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4212d23db6073cac",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T13:32:46.895730100Z",
     "start_time": "2024-02-27T13:32:46.885044900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from keras.src.layers import Dropout\n",
    "from keras import Model, Input\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable, GeocoderInsufficientPrivileges\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:19:46.536701600Z",
     "start_time": "2024-02-27T11:14:06.816179800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 18s 30ms/step - loss: 23861.4863 - val_loss: 20065.5254\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 18148.7207 - val_loss: 16717.2148\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 15423.0566 - val_loss: 14384.2949\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 13312.9268 - val_loss: 12474.0977\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 11561.8047 - val_loss: 10871.6084\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 10086.5498 - val_loss: 9516.6992\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 8845.8984 - val_loss: 8385.4111\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 7804.8374 - val_loss: 7436.6997\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 6939.0742 - val_loss: 6651.1621\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 6227.4697 - val_loss: 6012.8086\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5650.2930 - val_loss: 5496.5952\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 5189.2852 - val_loss: 5088.1860\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4831.0459 - val_loss: 4774.7783\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4557.0889 - val_loss: 4541.4419\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4352.8872 - val_loss: 4367.2676\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4207.0078 - val_loss: 4245.6118\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4105.8145 - val_loss: 4162.6343\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4038.6838 - val_loss: 4109.4014\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3996.0601 - val_loss: 4076.5627\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3970.3616 - val_loss: 4057.2827\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3955.7324 - val_loss: 4046.6533\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3947.7446 - val_loss: 4040.0730\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 3885.0718 - val_loss: 3910.3584\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3847.4607 - val_loss: 3901.4607\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3841.1223 - val_loss: 3896.9084\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3839.8875 - val_loss: 3882.3101\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3834.0906 - val_loss: 3879.7693\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3832.1587 - val_loss: 3885.9565\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3828.1321 - val_loss: 3876.2881\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3826.8003 - val_loss: 3874.8530\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3834.0400 - val_loss: 3881.3025\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4275 - val_loss: 3874.5701\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3828.8333 - val_loss: 3883.4172\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3828.9521 - val_loss: 3875.2771\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.8091 - val_loss: 3881.0376\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3828.7134 - val_loss: 3878.0745\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3828.8618 - val_loss: 3877.0139\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3830.5435 - val_loss: 3877.8984\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3824.5266 - val_loss: 3873.6372\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3826.3015 - val_loss: 3874.1130\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3826.3689 - val_loss: 3873.2375\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.3245 - val_loss: 3876.3303\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3825.7876 - val_loss: 3877.4006\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.8186 - val_loss: 3874.2388\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.6316 - val_loss: 3875.1208\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.1267 - val_loss: 3877.9824\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.4417 - val_loss: 3877.7490\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.6016 - val_loss: 3876.9219\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3823.8713 - val_loss: 3875.6565\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0671 - val_loss: 3876.2239\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.1772 - val_loss: 3879.3879\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3826.2246 - val_loss: 3876.5994\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3822.5339 - val_loss: 3880.3865\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3824.9729 - val_loss: 3878.2310\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3825.0625 - val_loss: 3883.0701\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.3101 - val_loss: 3875.8472\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.5886 - val_loss: 3879.5574\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.8313 - val_loss: 3878.4673\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3826.1643 - val_loss: 3875.4465\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3823.9377 - val_loss: 3885.9363\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4246 - val_loss: 3876.5662\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3825.0757 - val_loss: 3876.7437\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3825.4565 - val_loss: 3875.3464\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3823.6675 - val_loss: 3877.6216\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.6140 - val_loss: 3877.2637\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3824.2769 - val_loss: 3876.0371\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.9812 - val_loss: 3875.5210\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3823.9133 - val_loss: 3876.7234\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3823.8547 - val_loss: 3878.5608\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.5671 - val_loss: 3875.5212\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3825.2776 - val_loss: 3875.6309\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3823.8298 - val_loss: 3875.5674\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.2075 - val_loss: 3877.0784\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0662 - val_loss: 3875.8242\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.0854 - val_loss: 3875.9763\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3826.6956 - val_loss: 3878.5144\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.3279 - val_loss: 3877.3184\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.3586 - val_loss: 3877.4592\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.4353 - val_loss: 3877.4099\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.6301 - val_loss: 3878.7903\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.3999 - val_loss: 3879.8555\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8630 - val_loss: 3878.3064\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8503 - val_loss: 3876.9363\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.6611 - val_loss: 3878.5420\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.0757 - val_loss: 3877.4863\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.9822 - val_loss: 3877.0630\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3824.2847 - val_loss: 3877.1230\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.5103 - val_loss: 3875.7539\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.0662 - val_loss: 3883.1084\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3825.3303 - val_loss: 3880.3589\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3822.8054 - val_loss: 3876.8938\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.5635 - val_loss: 3881.8538\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8892 - val_loss: 3879.8062\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.2041 - val_loss: 3876.9072\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.0247 - val_loss: 3878.0864\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3823.6084 - val_loss: 3878.2808\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.8667 - val_loss: 3877.9888\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3824.5354 - val_loss: 3876.9771\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3821.7288 - val_loss: 3879.6726\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3823.1860 - val_loss: 3876.6028\n",
      "59/59 [==============================] - 5s 6ms/step\n",
      "Mean Squared Error: 4085.98140515532\n",
      "Root Mean Squared Error: 63.92168180793838\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545449918267e7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Mean Squared Error: 4084.3665521731436\n",
    "Root Mean Squared Error: 63.909049063283234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bffea0c4c40d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c168b4c71b26642c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:26:09.529018900Z",
     "start_time": "2024-02-27T11:19:46.554704100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 19s 30ms/step - loss: 22610.9805 - val_loss: 19545.8242\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 17630.6074 - val_loss: 16079.5811\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 14638.8467 - val_loss: 13463.6426\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 12284.7783 - val_loss: 11352.9814\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 10375.2920 - val_loss: 9635.1289\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 8828.1270 - val_loss: 8250.1982\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 7582.1943 - val_loss: 7140.2505\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 6595.2783 - val_loss: 6268.6548\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 5827.7852 - val_loss: 5599.9434\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 5244.1255 - val_loss: 5100.1445\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 4810.7319 - val_loss: 4731.8325\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4500.0112 - val_loss: 4473.6016\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 4286.1362 - val_loss: 4300.4780\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 4142.5884 - val_loss: 4185.8833\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 4052.9375 - val_loss: 4116.3208\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3999.8323 - val_loss: 4076.3035\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3970.0242 - val_loss: 4055.8064\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3954.1108 - val_loss: 4044.9666\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3904.0422 - val_loss: 3910.4749\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3846.6167 - val_loss: 3888.5029\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3822.8726 - val_loss: 3875.7903\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3810.5354 - val_loss: 3860.5298\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3797.3977 - val_loss: 3849.4619\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3790.9077 - val_loss: 3836.9346\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3779.5977 - val_loss: 3833.2429\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3776.8350 - val_loss: 3829.0452\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3771.4788 - val_loss: 3832.7090\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3768.1313 - val_loss: 3819.2783\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3755.6697 - val_loss: 3812.9482\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3745.0903 - val_loss: 3804.6538\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3733.0730 - val_loss: 3797.5244\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3730.2307 - val_loss: 3795.9480\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3720.4810 - val_loss: 3791.0547\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3716.2810 - val_loss: 3788.1628\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3716.1829 - val_loss: 3786.8489\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3711.8677 - val_loss: 3786.5203\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3709.4534 - val_loss: 3784.8625\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3712.2925 - val_loss: 3786.9956\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3709.6455 - val_loss: 3785.5991\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3709.2219 - val_loss: 3787.4312\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3708.2441 - val_loss: 3784.7751\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3706.2668 - val_loss: 3783.5898\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3702.4143 - val_loss: 3783.7261\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3704.4009 - val_loss: 3783.5591\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3702.2205 - val_loss: 3782.7170\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3700.9941 - val_loss: 3783.0415\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3700.1509 - val_loss: 3780.4180\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3697.0139 - val_loss: 3783.1035\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3697.8486 - val_loss: 3778.1829\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3687.0818 - val_loss: 3768.8853\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3674.4873 - val_loss: 3752.0229\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3663.7256 - val_loss: 3737.4036\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3647.0793 - val_loss: 3715.3782\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3618.2456 - val_loss: 3689.0974\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3583.5662 - val_loss: 3653.5881\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3563.3838 - val_loss: 3649.5046\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3553.7190 - val_loss: 3632.4697\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3540.6716 - val_loss: 3611.7627\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3517.0381 - val_loss: 3598.3137\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3508.2412 - val_loss: 3587.6907\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3492.6714 - val_loss: 3582.9771\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3478.2881 - val_loss: 3565.9875\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3465.7896 - val_loss: 3549.5603\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3456.5701 - val_loss: 3552.3584\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3452.6272 - val_loss: 3550.7612\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3452.0112 - val_loss: 3549.4253\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3449.4707 - val_loss: 3547.1646\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3448.3267 - val_loss: 3546.5376\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3445.8494 - val_loss: 3542.3235\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3446.2563 - val_loss: 3545.7463\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3444.6882 - val_loss: 3544.1489\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 3444.7720 - val_loss: 3536.7776\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3440.9829 - val_loss: 3535.2637\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3433.8767 - val_loss: 3529.3071\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3430.7222 - val_loss: 3528.7300\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3429.9246 - val_loss: 3527.0754\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3429.2385 - val_loss: 3526.1809\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3427.1323 - val_loss: 3525.1675\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3431.8157 - val_loss: 3524.5916\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3427.6729 - val_loss: 3523.9407\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3426.7246 - val_loss: 3524.3352\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.9951 - val_loss: 3523.6885\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.7344 - val_loss: 3522.2429\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3424.4871 - val_loss: 3514.3193\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3423.2007 - val_loss: 3515.4207\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3419.7849 - val_loss: 3514.9656\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3417.3689 - val_loss: 3511.5088\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.4443 - val_loss: 3510.6833\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.7197 - val_loss: 3511.8320\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3414.2063 - val_loss: 3499.9824\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3415.4224 - val_loss: 3511.0354\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3413.8137 - val_loss: 3507.1670\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3413.3850 - val_loss: 3508.3218\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3412.7922 - val_loss: 3507.0444\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3411.7185 - val_loss: 3502.9880\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 3408.2603 - val_loss: 3498.9900\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3407.2324 - val_loss: 3500.3154\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3407.7351 - val_loss: 3496.9302\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3405.5603 - val_loss: 3496.7400\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 3405.0635 - val_loss: 3495.0344\n",
      "59/59 [==============================] - 2s 7ms/step\n",
      "RMSE: 60.797518835041835\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb27b357a0a0af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n",
    "RMSE: 60.78381977426994"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "experience_mapping for ['experience_level']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed465217996aeb0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 14s 29ms/step - loss: 22351.6348 - val_loss: 19712.3477\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 17930.6953 - val_loss: 16432.7637\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 14972.0225 - val_loss: 13767.4268\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 12557.3984 - val_loss: 11591.9756\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 10582.8506 - val_loss: 9813.1934\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 8975.1074 - val_loss: 8373.9229\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 7685.1714 - val_loss: 7223.0566\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 6663.7358 - val_loss: 6325.9531\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 5870.7251 - val_loss: 5632.1987\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 5267.9644 - val_loss: 5116.2061\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 4822.2969 - val_loss: 4738.8813\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4504.9482 - val_loss: 4475.7485\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4286.6465 - val_loss: 4297.8530\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 4142.3589 - val_loss: 4185.4512\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 4052.1890 - val_loss: 4116.3042\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3998.6453 - val_loss: 4076.2983\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3968.6682 - val_loss: 4054.2366\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3945.6614 - val_loss: 4000.0139\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 4141.6411 - val_loss: 4108.7886\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3941.8108 - val_loss: 3534.5583\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3342.5930 - val_loss: 3370.2781\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3219.0601 - val_loss: 3305.7490\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3165.0923 - val_loss: 3263.0730\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 3126.7009 - val_loss: 3244.3845\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 3109.6702 - val_loss: 3229.9492\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3098.4148 - val_loss: 3217.9089\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3090.3162 - val_loss: 3217.7244\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 3085.2378 - val_loss: 3205.5754\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3088.0217 - val_loss: 3200.8279\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3080.6343 - val_loss: 3195.9343\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3070.5146 - val_loss: 3253.2417\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3084.1658 - val_loss: 3195.8047\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3068.5815 - val_loss: 3190.5139\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3068.2319 - val_loss: 3191.7493\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3074.5342 - val_loss: 3188.5503\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3066.3450 - val_loss: 3190.5444\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3070.5720 - val_loss: 3186.2483\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3070.3635 - val_loss: 3191.6489\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3068.4705 - val_loss: 3195.7666\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3064.9792 - val_loss: 3186.7197\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3061.1709 - val_loss: 3198.9609\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3060.8657 - val_loss: 3186.5571\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3061.5149 - val_loss: 3183.9456\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3057.8445 - val_loss: 3183.2629\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3057.7036 - val_loss: 3181.0930\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3056.6741 - val_loss: 3179.8552\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3055.9316 - val_loss: 3181.7085\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3053.3193 - val_loss: 3180.1919\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3047.4797 - val_loss: 3181.9490\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 6s 28ms/step - loss: 3056.2661 - val_loss: 3187.3684\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 7s 34ms/step - loss: 3051.5625 - val_loss: 3182.5618\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3053.3525 - val_loss: 3179.6685\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3047.7881 - val_loss: 3181.9790\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3046.6150 - val_loss: 3180.9192\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3046.0579 - val_loss: 3180.4624\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3043.0059 - val_loss: 3176.8625\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3040.8828 - val_loss: 3186.5593\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3042.1931 - val_loss: 3178.4285\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3035.7544 - val_loss: 3178.2144\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3040.1995 - val_loss: 3176.3589\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3035.5432 - val_loss: 3178.0867\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3032.9473 - val_loss: 3185.0825\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3032.5789 - val_loss: 3177.6753\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3034.0859 - val_loss: 3178.9585\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3036.7563 - val_loss: 3179.8235\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3032.0010 - val_loss: 3187.1602\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3031.8408 - val_loss: 3177.3152\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3033.0293 - val_loss: 3177.2112\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3030.0066 - val_loss: 3177.0081\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3029.0764 - val_loss: 3177.7783\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3027.8171 - val_loss: 3176.6899\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 3029.5659 - val_loss: 3176.4307\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3025.0579 - val_loss: 3178.7561\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3026.4871 - val_loss: 3177.3547\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 3025.1777 - val_loss: 3176.0283\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 8s 35ms/step - loss: 3026.2229 - val_loss: 3174.6711\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3024.9978 - val_loss: 3175.3118\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 6s 27ms/step - loss: 3022.4089 - val_loss: 3177.2883\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3022.6560 - val_loss: 3189.7944\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.9143 - val_loss: 3175.3044\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.3396 - val_loss: 3173.9946\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3026.9253 - val_loss: 3176.6106\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3023.0049 - val_loss: 3178.3164\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3023.4946 - val_loss: 3175.8706\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3020.9761 - val_loss: 3178.5720\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3023.0847 - val_loss: 3178.0151\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 3016.9658 - val_loss: 3178.8557\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 3024.4795 - val_loss: 3179.8066\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 3020.3616 - val_loss: 3178.1692\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3018.8362 - val_loss: 3175.9065\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 3020.5957 - val_loss: 3175.3743\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3022.7717 - val_loss: 3177.9973\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3018.4238 - val_loss: 3176.5073\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 3018.5444 - val_loss: 3177.3538\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3021.2803 - val_loss: 3179.8037\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3020.4229 - val_loss: 3179.0063\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3018.3430 - val_loss: 3178.0164\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 3017.2820 - val_loss: 3177.7717\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 5s 26ms/step - loss: 3016.6323 - val_loss: 3178.0701\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 3017.3000 - val_loss: 3184.4165\n",
      "59/59 [==============================] - 5s 8ms/step\n",
      "RMSE: 57.5500774333776\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T11:34:14.295240400Z",
     "start_time": "2024-02-27T11:26:09.536579800Z"
    }
   },
   "id": "5655332e67e284ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "experience_mapping for ['experience_level']\n",
    "RMSE: 57.54844132269867"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34367b8406b19476"
  },
  {
   "cell_type": "markdown",
   "source": [
    "distance from  [\"employee_residence\"] - [\"company_location\"] "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102f827262b8454c"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 5s 10ms/step - loss: 22209.9219 - val_loss: 19905.7305\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 18140.7090 - val_loss: 16666.3691\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 15220.4756 - val_loss: 14026.5635\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 12806.6582 - val_loss: 11833.3740\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 10813.9014 - val_loss: 10034.2988\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 9181.3184 - val_loss: 8564.7402\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 7859.4482 - val_loss: 7382.5059\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 6807.5386 - val_loss: 6454.1001\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 5985.7378 - val_loss: 5735.3140\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 5357.8550 - val_loss: 5193.2725\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 4890.1719 - val_loss: 4797.5352\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 4552.1602 - val_loss: 4514.7969\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 4317.6914 - val_loss: 4324.5552\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 4163.3354 - val_loss: 4200.8418\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 4065.2119 - val_loss: 4125.2588\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 4048.3896 - val_loss: 4081.8130\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3972.7422 - val_loss: 4057.9197\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3955.1426 - val_loss: 4045.5730\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3947.1643 - val_loss: 4040.4333\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3943.6213 - val_loss: 4038.0989\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3942.0056 - val_loss: 4037.3035\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3941.3669 - val_loss: 4036.6379\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3940.9729 - val_loss: 4036.4927\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3941.0203 - val_loss: 4036.3665\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3940.8687 - val_loss: 4036.0481\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3940.1272 - val_loss: 4034.3657\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3929.4756 - val_loss: 3931.5054\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3852.0732 - val_loss: 3904.7097\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3840.0388 - val_loss: 3923.7146\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3832.7917 - val_loss: 3894.5820\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3833.5977 - val_loss: 3890.5125\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3813.9849 - val_loss: 3858.6345\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3505.6707 - val_loss: 2877.1775\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 2211.5393 - val_loss: 1952.4901\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 1669.2555 - val_loss: 1571.1206\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 1410.4470 - val_loss: 1369.8751\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 1257.0475 - val_loss: 1239.9946\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 1151.0308 - val_loss: 1146.5381\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 1067.4998 - val_loss: 1085.2574\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 997.5721 - val_loss: 1021.7770\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 952.9005 - val_loss: 970.8672\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 908.1080 - val_loss: 915.8950\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 877.1107 - val_loss: 896.8228\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 848.3683 - val_loss: 865.2039\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 831.5706 - val_loss: 848.4236\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 815.9756 - val_loss: 842.2473\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 793.1921 - val_loss: 818.9344\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 788.5035 - val_loss: 794.0857\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 764.7144 - val_loss: 768.3085\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 755.0744 - val_loss: 761.8422\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 749.6127 - val_loss: 747.9310\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 744.5636 - val_loss: 748.9293\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 737.4395 - val_loss: 720.1395\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 731.5996 - val_loss: 773.1157\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 708.1517 - val_loss: 724.6913\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 715.6827 - val_loss: 701.7902\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 709.7866 - val_loss: 707.2952\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 704.4362 - val_loss: 709.7321\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 702.9977 - val_loss: 719.4321\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 697.7178 - val_loss: 694.4110\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 692.0569 - val_loss: 692.7848\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 683.6619 - val_loss: 678.8051\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 687.0145 - val_loss: 723.5125\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 690.2155 - val_loss: 683.3715\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 671.7876 - val_loss: 673.6070\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 682.1393 - val_loss: 665.8517\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 671.3355 - val_loss: 667.6693\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 674.6758 - val_loss: 683.1544\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 688.9445 - val_loss: 677.2917\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 668.1001 - val_loss: 667.0107\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 680.7266 - val_loss: 694.0287\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 671.2885 - val_loss: 649.9679\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 673.0151 - val_loss: 674.8224\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 651.3100 - val_loss: 646.0217\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 656.0215 - val_loss: 667.7778\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 664.5816 - val_loss: 646.8785\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 660.9236 - val_loss: 674.6119\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 663.6735 - val_loss: 662.2480\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 661.9822 - val_loss: 642.1733\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 662.0068 - val_loss: 659.1960\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 660.1373 - val_loss: 640.6716\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 653.0328 - val_loss: 689.0247\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 657.5766 - val_loss: 651.9662\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 659.9797 - val_loss: 640.2460\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 660.9749 - val_loss: 644.3508\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 652.4354 - val_loss: 651.6768\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 652.8082 - val_loss: 651.9318\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 646.1043 - val_loss: 647.2490\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 651.4928 - val_loss: 646.3729\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 649.8311 - val_loss: 634.1309\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 655.3583 - val_loss: 644.1111\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 663.9994 - val_loss: 628.8507\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 640.5135 - val_loss: 651.1595\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 644.0817 - val_loss: 703.0563\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 650.2298 - val_loss: 731.2580\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 655.0898 - val_loss: 649.7682\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 641.6697 - val_loss: 646.3264\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 646.7662 - val_loss: 644.4093\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 644.9138 - val_loss: 651.9128\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 640.4169 - val_loss: 619.7565\n",
      "59/59 [==============================] - 2s 3ms/step\n",
      "RMSE: 25.531453514062534\n"
     ]
    }
   ],
   "source": [
    "location_coordinates = {'Germany': (51.1638175, 10.4478313), 'United States': (39.7837304, -100.445882),\n",
    "                        'United Kingdom': (54.7023545, -3.2765753), 'Canada': (61.0666922, -107.991707),\n",
    "                        'Spain': (39.3260685, -4.8379791), 'Ireland': (52.865196, -7.9794599),\n",
    "                        'South Africa': (-28.8166236, 24.991639), 'Poland': (52.215933, 19.134422),\n",
    "                        'France': (46.603354, 1.8883335), 'Netherlands': (52.2434979, 5.6343227),\n",
    "                        'Luxembourg': (49.6112768, 6.129799), 'Lithuania': (55.3500003, 23.7499997),\n",
    "                        'Portugal': (39.6621648, -8.1353519), 'Gibraltar': (36.1285933, -5.3474761),\n",
    "                        'Australia': (-24.7761086, 134.755), 'Colombia': (4.099917, -72.9088133),\n",
    "                        'Ukraine': (49.4871968, 31.2718321), 'Slovenia': (46.1199444, 14.8153333),\n",
    "                        'Romania': (45.9852129, 24.6859225), 'Greece': (43.2097838, -77.6930602),\n",
    "                        'India': (22.3511148, 78.6677428), 'Latvia': (56.8406494, 24.7537645),\n",
    "                        'Mauritius': (-20.2759451, 57.5703566), 'Russia': (64.6863136, 97.7453061),\n",
    "                        'Italy': (42.6384261, 12.674297), 'South Korea': (36.638392, 127.6961188),\n",
    "                        'Estonia': (58.7523778, 25.3319078), 'Czech Republic': (49.7439047, 15.3381061),\n",
    "                        'Brazil': (-10.3333333, -53.2), 'Qatar': (25.3336984, 51.2295295),\n",
    "                        'Kenya': (1.4419683, 38.4313975), 'Denmark': (55.670249, 10.3333283),\n",
    "                        'Ghana': (8.0300284, -1.0800271), 'Sweden': (59.6749712, 14.5208584),\n",
    "                        'Turkey': (38.9597594, 34.9249653), 'Switzerland': (46.7985624, 8.2319736),\n",
    "                        'Andorra': (42.5407167, 1.5732033), 'Ecuador': (-1.3397668, -79.3666965),\n",
    "                        'Mexico': (19.4326296, -99.1331785), 'Israel': (30.8124247, 34.8594762),\n",
    "                        'Nigeria': (9.6000359, 7.9999721), 'Saudi Arabia': (25.6242618, 42.3528328),\n",
    "                        'Argentina': (-34.9964963, -64.9672817), 'Japan': (36.5748441, 139.2394179),\n",
    "                        'Central African Republic': (7.0323598, 19.9981227), 'Finland': (63.2467777, 25.9209164),\n",
    "                        'Singapore': (1.357107, 103.8194992), 'Croatia': (45.3658443, 15.6575209),\n",
    "                        'Armenia': (4.491976149999999, -75.74135085294314),\n",
    "                        'Bosnia and Herzegovina': (44.3053476, 17.5961467), 'Pakistan': (30.3308401, 71.247499),\n",
    "                        'Iran': (32.6475314, 54.5643516), 'Bahamas': (24.7736546, -78.0000547),\n",
    "                        'Austria': (47.59397, 14.12456), 'Puerto Rico': (18.2247706, -66.4858295),\n",
    "                        'American Samoa': (-14.297124, -170.7131481), 'Thailand': (13.03876215, 101.70017611907599),\n",
    "                        'Philippines': (12.7503486, 122.7312101), 'Belgium': (50.6402809, 4.6667145),\n",
    "                        'Egypt': (26.2540493, 29.2675469), 'Indonesia': (-2.4833826, 117.8902853),\n",
    "                        'United Arab Emirates': (24.0002488, 53.9994829), 'Malaysia': (4.5693754, 102.2656823),\n",
    "                        'Honduras': (15.2572432, -86.0755145), 'Algeria': (28.0000272, 2.9999825),\n",
    "                        'Iraq': (33.0955793, 44.1749775), 'China': (35.000074, 104.999927),\n",
    "                        'New Zealand': (-41.5000831, 172.8344077), 'Moldova': (47.2879608, 28.5670941),\n",
    "                        'Malta': (35.8885993, 14.4476911), 'Uganda': (1.5333554, 32.2166578),\n",
    "                        'Tunisia': (36.8002068, 10.1857757), 'Peru': (-6.8699697, -75.0458515),\n",
    "                        'Uzbekistan': (41.32373, 63.9528098), 'Georgia': (32.3293809, -83.1137366),\n",
    "                        'Kuwait': (29.3796532, 47.9734174), 'Cyprus': (34.9174159, 32.889902651331866),\n",
    "                        'Costa Rica': (10.2735633, -84.0739102), 'Chile': (-31.7613365, -71.3187697),\n",
    "                        'Bolivia': (-17.0568696, -64.9912286), 'Dominican Republic': (19.0974031, -70.3028026),\n",
    "                        'Vietnam': (15.9266657, 107.9650855), 'Bulgaria': (42.6073975, 25.4856617),\n",
    "                        'Jersey': (49.2214561, -2.1358386), 'Serbia': (44.024322850000004, 21.07657433209902),\n",
    "                        'Hong Kong': (22.350627, 114.1849161)}\n",
    "\n",
    "# Haversine function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = 6371 * c  # Radius of the Earth in kilometers\n",
    "\n",
    "    return distance\n",
    "\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Calculate distances and add them to the DataFrame\n",
    "df['distance_company_to_residence'] = df.apply(lambda row: haversine(*location_coordinates[row['company_location']], *location_coordinates[row['employee_residence']]), axis=1)\n",
    "\n",
    "# Load your data\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "\n",
    "# Calculate the percentile rank of each salary within its job category\n",
    "df['Percentile'] = df.groupby('job_category')['salary'].rank(pct=True)\n",
    "\n",
    "# Normalize the percentile ranks to a scale of 0 to 1\n",
    "min_percentile = df['Percentile'].min()\n",
    "max_percentile = df['Percentile'].max()\n",
    "df['Normalized_Salary_within_Job_Category'] = (df['Percentile'] - min_percentile) / (max_percentile - min_percentile)\n",
    "\n",
    "# Drop the temporary 'Percentile' column if you don't need it anymore\n",
    "df.drop(columns=['Percentile'], inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:29.287207900Z",
     "start_time": "2024-02-27T14:29:17.322749200Z"
    }
   },
   "id": "8365c9c64a0687ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalized Salary within Job Category\n",
    "RMSE: 25.531453514062534"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4821ba084594397"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4212d23db6073cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T13:32:46.895730100Z",
     "start_time": "2024-02-27T13:32:46.885044900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from keras.src.layers import Dropout\n",
    "from keras import Model, Input\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable, GeocoderInsufficientPrivileges\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T11:19:46.536701600Z",
     "start_time": "2024-02-27T11:14:06.816179800Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 7s 11ms/step - loss: 23874.5039 - val_loss: 20139.7578\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 18251.5410 - val_loss: 16831.9219\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 15536.2236 - val_loss: 14495.8730\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 13423.3789 - val_loss: 12579.5537\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 11662.9463 - val_loss: 10970.6836\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 10177.6260 - val_loss: 9605.9043\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 8925.4336 - val_loss: 8458.3672\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 7872.8203 - val_loss: 7498.6279\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 6997.0576 - val_loss: 6705.0859\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 6275.9307 - val_loss: 6055.2915\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 5690.9780 - val_loss: 5533.1768\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 5224.3081 - val_loss: 5121.1479\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 4858.4478 - val_loss: 4799.8818\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 4577.6904 - val_loss: 4557.6948\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 4368.8159 - val_loss: 4379.6704\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 4218.3701 - val_loss: 4254.6069\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 4113.5532 - val_loss: 4168.2603\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 4043.1135 - val_loss: 4112.7949\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3998.7083 - val_loss: 4078.4766\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3971.7285 - val_loss: 4058.3638\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3956.7046 - val_loss: 4047.5730\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3948.0017 - val_loss: 4040.8420\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3940.9458 - val_loss: 3976.2107\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3874.7354 - val_loss: 3908.1321\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3844.3059 - val_loss: 3914.6843\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3840.7500 - val_loss: 3885.0774\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3832.2896 - val_loss: 3886.6609\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3836.4233 - val_loss: 3877.2253\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3829.3687 - val_loss: 3883.4285\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 3827.7864 - val_loss: 3885.3152\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3831.9312 - val_loss: 3883.7375\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3833.4124 - val_loss: 3875.2764\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3828.0222 - val_loss: 3883.7498\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3829.4102 - val_loss: 3880.3030\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3825.3516 - val_loss: 3878.3337\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3826.6387 - val_loss: 3876.6445\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 3827.1499 - val_loss: 3880.2661\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3827.8235 - val_loss: 3878.2856\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3827.0032 - val_loss: 3881.2983\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3827.8735 - val_loss: 3879.1028\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3824.6345 - val_loss: 3876.5237\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 3825.0088 - val_loss: 3877.1592\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3825.9724 - val_loss: 3875.3547\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.3662 - val_loss: 3875.5146\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.6394 - val_loss: 3876.7498\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3826.8276 - val_loss: 3876.4521\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3826.4517 - val_loss: 3875.7661\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3825.8230 - val_loss: 3876.4346\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3825.2000 - val_loss: 3879.2854\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3826.1685 - val_loss: 3882.1621\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.7661 - val_loss: 3875.3538\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3825.4609 - val_loss: 3875.3438\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.4751 - val_loss: 3876.6929\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3826.2366 - val_loss: 3876.1174\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.4954 - val_loss: 3880.9626\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.6365 - val_loss: 3876.0901\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.8823 - val_loss: 3875.9316\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3821.4470 - val_loss: 3876.8928\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3824.6968 - val_loss: 3876.8501\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.9792 - val_loss: 3876.4434\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.4387 - val_loss: 3878.3743\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.7766 - val_loss: 3875.8198\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.5693 - val_loss: 3878.9512\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3826.1030 - val_loss: 3878.1658\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.8269 - val_loss: 3877.1599\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.5144 - val_loss: 3880.3591\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3825.0210 - val_loss: 3877.2383\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.7495 - val_loss: 3875.8203\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.5439 - val_loss: 3878.2671\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.0710 - val_loss: 3876.7915\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.8752 - val_loss: 3875.9993\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.7859 - val_loss: 3877.8303\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.4590 - val_loss: 3877.4736\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3825.0747 - val_loss: 3876.5037\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.4011 - val_loss: 3878.0120\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.3167 - val_loss: 3878.5439\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.8157 - val_loss: 3876.3374\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.5757 - val_loss: 3877.2319\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.6108 - val_loss: 3876.2056\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.7546 - val_loss: 3876.3599\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.7527 - val_loss: 3876.1519\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.4521 - val_loss: 3877.3103\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.2036 - val_loss: 3877.6089\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.0955 - val_loss: 3876.3467\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.7205 - val_loss: 3876.5447\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.2688 - val_loss: 3876.4062\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.1389 - val_loss: 3878.2524\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.4099 - val_loss: 3876.6211\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.3477 - val_loss: 3876.6318\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.0076 - val_loss: 3876.4153\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.8677 - val_loss: 3876.9583\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3825.4382 - val_loss: 3875.7681\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.3721 - val_loss: 3877.3118\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.1108 - val_loss: 3876.0474\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.9734 - val_loss: 3876.0789\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.7795 - val_loss: 3875.8691\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3823.7258 - val_loss: 3875.7720\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3824.0325 - val_loss: 3877.0942\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 3822.8066 - val_loss: 3878.5461\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 3823.5840 - val_loss: 3877.6526\n",
      "59/59 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 4085.758812696294\n",
      "Root Mean Squared Error: 63.91994064997475\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b545449918267e7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Mean Squared Error: 4084.3665521731436\n",
    "Root Mean Squared Error: 63.909049063283234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6bffea0c4c40d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c168b4c71b26642c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T11:26:09.529018900Z",
     "start_time": "2024-02-27T11:19:46.554704100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 50s 16ms/step - loss: 22391.4121 - val_loss: 19288.1348\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 17403.2539 - val_loss: 15874.2588\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 14443.8457 - val_loss: 13284.2080\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 12113.7109 - val_loss: 11194.1738\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 10228.8760 - val_loss: 9501.7842\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 8701.6094 - val_loss: 8132.6328\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 7477.5791 - val_loss: 7046.3184\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 6509.3374 - val_loss: 6192.1763\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 5760.6543 - val_loss: 5541.4150\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 5193.0381 - val_loss: 5054.1504\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4773.0962 - val_loss: 4701.0796\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 4472.7598 - val_loss: 4452.9321\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 4265.7681 - val_loss: 4283.9429\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4129.4131 - val_loss: 4175.7856\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 4045.0996 - val_loss: 4110.4614\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3995.5012 - val_loss: 4074.3909\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3967.1711 - val_loss: 4053.2620\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3946.4409 - val_loss: 4031.8716\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3904.7280 - val_loss: 3921.6963\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3850.6208 - val_loss: 3921.3115\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3831.9478 - val_loss: 3882.1299\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3822.5139 - val_loss: 3873.4106\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3811.0505 - val_loss: 3858.9102\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3804.9844 - val_loss: 3858.3801\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3801.9192 - val_loss: 3850.2507\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3800.9868 - val_loss: 3849.7603\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3796.1511 - val_loss: 3847.0034\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3794.6592 - val_loss: 3845.9919\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3791.4209 - val_loss: 3838.3125\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3780.2339 - val_loss: 3830.3838\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3771.5378 - val_loss: 3825.1294\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3764.3323 - val_loss: 3817.0852\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3761.5090 - val_loss: 3815.4158\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 3753.4299 - val_loss: 3810.5227\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3750.0884 - val_loss: 3804.9636\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3738.7637 - val_loss: 3803.1331\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3733.6060 - val_loss: 3798.9312\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3725.2722 - val_loss: 3790.4346\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3715.7734 - val_loss: 3787.0144\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3710.3291 - val_loss: 3787.0181\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3709.8708 - val_loss: 3787.1638\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3707.5833 - val_loss: 3785.7310\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3706.1582 - val_loss: 3785.5491\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3700.6792 - val_loss: 3781.1816\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3697.5994 - val_loss: 3777.8481\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3688.5737 - val_loss: 3771.1670\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3684.3047 - val_loss: 3766.9897\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3677.4744 - val_loss: 3762.2292\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3655.0459 - val_loss: 3719.5208\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3618.3567 - val_loss: 3694.8208\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3570.6721 - val_loss: 3639.6047\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3538.7915 - val_loss: 3621.1907\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3524.9077 - val_loss: 3604.1606\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3501.7957 - val_loss: 3581.9761\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3476.2041 - val_loss: 3559.5234\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3461.3677 - val_loss: 3553.4707\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3456.4309 - val_loss: 3549.8442\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3449.5923 - val_loss: 3544.1565\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3442.6792 - val_loss: 3538.9070\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3439.2234 - val_loss: 3533.7563\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3435.4604 - val_loss: 3531.1448\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3431.5588 - val_loss: 3533.2112\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3422.3440 - val_loss: 3512.9856\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3419.5801 - val_loss: 3512.7227\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3421.8464 - val_loss: 3508.4736\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3412.5667 - val_loss: 3503.9597\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3414.0503 - val_loss: 3500.8689\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3412.0974 - val_loss: 3497.5251\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3408.9285 - val_loss: 3494.8872\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3409.0762 - val_loss: 3494.3618\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3409.4534 - val_loss: 3498.0657\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3407.9312 - val_loss: 3492.9875\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3406.9197 - val_loss: 3498.4734\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3407.8767 - val_loss: 3497.9192\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3406.4814 - val_loss: 3495.9697\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3406.4717 - val_loss: 3494.9900\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3406.4167 - val_loss: 3492.9062\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3409.6709 - val_loss: 3494.1558\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3405.2561 - val_loss: 3493.8630\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3405.5278 - val_loss: 3492.2539\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3405.4868 - val_loss: 3493.8911\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3405.6926 - val_loss: 3493.5935\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3404.5056 - val_loss: 3491.9365\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3404.0376 - val_loss: 3493.3225\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3403.7668 - val_loss: 3490.6326\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3404.4224 - val_loss: 3493.2988\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3403.7979 - val_loss: 3491.1099\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3403.4155 - val_loss: 3492.6763\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3402.9304 - val_loss: 3492.7629\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3404.4583 - val_loss: 3492.6555\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3402.4233 - val_loss: 3492.5920\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3406.0149 - val_loss: 3492.8008\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3402.6426 - val_loss: 3491.7798\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3403.3242 - val_loss: 3492.5930\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3402.2512 - val_loss: 3492.6118\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3405.0327 - val_loss: 3491.0466\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3403.0232 - val_loss: 3491.0955\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3402.6343 - val_loss: 3491.6511\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3402.6909 - val_loss: 3491.4316\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3403.2222 - val_loss: 3491.3606\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "RMSE: 60.77914702330908\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb27b357a0a0af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "['salary_in_usd'] / ['salary'] \n",
    "RMSE: 60.78381977426994"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed465217996aeb0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "experience_mapping for ['experience_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5655332e67e284ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T11:34:14.295240400Z",
     "start_time": "2024-02-27T11:26:09.536579800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 10s 19ms/step - loss: 21996.9043 - val_loss: 19304.7539\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 17552.1191 - val_loss: 16081.4072\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 14645.5410 - val_loss: 13461.4102\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 12270.4336 - val_loss: 11323.5312\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 10334.7119 - val_loss: 9585.7695\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 8767.9404 - val_loss: 8183.9673\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 7513.6885 - val_loss: 7070.1533\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 6524.6396 - val_loss: 6198.6958\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 5759.7139 - val_loss: 5535.7949\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 5183.0591 - val_loss: 5042.4277\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4761.9819 - val_loss: 4687.9946\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4462.9180 - val_loss: 4440.6982\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4258.2139 - val_loss: 4276.0479\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 4124.2007 - val_loss: 4169.8740\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4040.9805 - val_loss: 4107.5786\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3991.9258 - val_loss: 4071.4409\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3964.9153 - val_loss: 4049.5691\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3921.8474 - val_loss: 3992.5598\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3866.3530 - val_loss: 3918.4329\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3829.6414 - val_loss: 3887.0210\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3794.0974 - val_loss: 3858.4185\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3771.4666 - val_loss: 3842.8779\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3758.8411 - val_loss: 3812.7871\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3503.9207 - val_loss: 3415.0771\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3187.4641 - val_loss: 3249.8789\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3105.1741 - val_loss: 3216.7761\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3082.3228 - val_loss: 3227.0134\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3073.5522 - val_loss: 3206.7939\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3058.1746 - val_loss: 3207.1111\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3060.2996 - val_loss: 3204.9473\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3054.1082 - val_loss: 3200.0447\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3053.0039 - val_loss: 3198.5063\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3048.1875 - val_loss: 3203.3464\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3049.0088 - val_loss: 3198.4712\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3047.1335 - val_loss: 3194.9380\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 3048.6726 - val_loss: 3195.0520\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 3043.6001 - val_loss: 3192.8384\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3045.4504 - val_loss: 3188.2830\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3048.2517 - val_loss: 3191.9153\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3046.3950 - val_loss: 3198.0276\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3046.9031 - val_loss: 3189.6797\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3037.2244 - val_loss: 3200.9583\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3042.5046 - val_loss: 3190.9272\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3039.8093 - val_loss: 3185.8425\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3038.3455 - val_loss: 3194.4646\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3040.1318 - val_loss: 3187.4436\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3035.6704 - val_loss: 3189.4634\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 3037.4622 - val_loss: 3185.2334\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3036.5586 - val_loss: 3190.3154\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3035.6819 - val_loss: 3192.6799\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3035.2712 - val_loss: 3183.2483\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3034.2302 - val_loss: 3188.2390\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3035.3105 - val_loss: 3183.9607\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3033.5520 - val_loss: 3186.2144\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3029.8677 - val_loss: 3189.6782\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 3034.7449 - val_loss: 3188.6292\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3032.5701 - val_loss: 3183.9753\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3030.5098 - val_loss: 3187.1255\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3028.5476 - val_loss: 3188.1318\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3031.3438 - val_loss: 3186.2625\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3028.7373 - val_loss: 3194.2917\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3030.2664 - val_loss: 3182.4248\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3028.8186 - val_loss: 3186.2856\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3026.7222 - val_loss: 3196.0334\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 3030.2590 - val_loss: 3178.3557\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3026.4932 - val_loss: 3186.0947\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3028.9597 - val_loss: 3185.0461\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3026.6167 - val_loss: 3180.3674\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3025.7339 - val_loss: 3184.0315\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3026.0183 - val_loss: 3186.6663\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3024.1555 - val_loss: 3186.6218\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3028.2915 - val_loss: 3186.0051\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3027.2239 - val_loss: 3180.7427\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 3025.0845 - val_loss: 3186.3318\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3027.9001 - val_loss: 3180.9692\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3027.2605 - val_loss: 3181.6702\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3023.4871 - val_loss: 3181.2607\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3026.4746 - val_loss: 3180.8794\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3024.2102 - val_loss: 3180.6748\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3021.6309 - val_loss: 3182.5364\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.9438 - val_loss: 3180.5063\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3023.2625 - val_loss: 3181.0247\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 3022.0393 - val_loss: 3180.7954\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.3032 - val_loss: 3179.7588\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.7366 - val_loss: 3181.0190\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.8794 - val_loss: 3180.7334\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3017.5254 - val_loss: 3182.7000\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3022.4998 - val_loss: 3180.7327\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3018.3279 - val_loss: 3179.3420\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3016.4192 - val_loss: 3181.9939\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.5276 - val_loss: 3183.4561\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3020.9954 - val_loss: 3183.3979\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3019.1907 - val_loss: 3183.1609\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3017.4587 - val_loss: 3180.5508\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3017.7844 - val_loss: 3178.1675\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3016.9211 - val_loss: 3181.0098\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 3018.1140 - val_loss: 3182.4111\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3017.9153 - val_loss: 3183.5884\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 3015.1841 - val_loss: 3184.4436\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3018.3958 - val_loss: 3181.4602\n",
      "59/59 [==============================] - 1s 3ms/step\n",
      "RMSE: 57.538534551124236\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34367b8406b19476",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "experience_mapping for ['experience_level']\n",
    "RMSE: 57.54844132269867"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f827262b8454c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "distance from  [\"employee_residence\"] - [\"company_location\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8365c9c64a0687ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T14:32:29.287207900Z",
     "start_time": "2024-02-27T14:29:17.322749200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 10s 19ms/step - loss: 21812.9199 - val_loss: 19512.8633\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 17793.7441 - val_loss: 16336.7334\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 14902.7871 - val_loss: 13727.7686\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 12531.8887 - val_loss: 11579.5352\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 10582.1504 - val_loss: 9820.7744\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 8988.8584 - val_loss: 8384.9834\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 7700.0137 - val_loss: 7240.5928\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 6676.1836 - val_loss: 6335.2036\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 5881.8696 - val_loss: 5644.6968\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 5276.9141 - val_loss: 5124.3477\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4829.6851 - val_loss: 4746.5088\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 4509.6553 - val_loss: 4479.3672\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 4290.1626 - val_loss: 4301.4395\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 4144.7334 - val_loss: 4185.7559\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 4062.2271 - val_loss: 4116.4658\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3999.4180 - val_loss: 4076.9045\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3969.0923 - val_loss: 4055.3794\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3953.3518 - val_loss: 4044.7493\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3946.3584 - val_loss: 4039.7820\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3943.0427 - val_loss: 4037.7710\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3941.9380 - val_loss: 4036.9099\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.3928 - val_loss: 4036.8291\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3941.0715 - val_loss: 4036.5835\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 12ms/step - loss: 3941.3154 - val_loss: 4036.4355\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3941.1343 - val_loss: 4036.1597\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3942.2949 - val_loss: 4036.4421\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.2170 - val_loss: 4036.6909\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.3203 - val_loss: 4036.6748\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.2336 - val_loss: 4036.6589\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.1831 - val_loss: 4036.6985\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3941.1653 - val_loss: 4036.6118\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 3941.4194 - val_loss: 4036.5828\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3941.0938 - val_loss: 4036.4880\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3939.4121 - val_loss: 4023.3611\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 3889.2446 - val_loss: 3913.4470\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3840.1094 - val_loss: 3901.0288\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3842.4924 - val_loss: 3899.3364\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 3836.1357 - val_loss: 3910.1389\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 3687.4897 - val_loss: 3186.6074\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 2352.7466 - val_loss: 1892.0239\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 1662.7407 - val_loss: 1561.8672\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 1412.2383 - val_loss: 1379.5756\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 1239.8284 - val_loss: 1235.5983\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 1127.8040 - val_loss: 1128.4719\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 1056.3967 - val_loss: 1057.3790\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 986.6675 - val_loss: 999.3775\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 943.4862 - val_loss: 976.5591\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 907.8714 - val_loss: 930.4296\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 869.3564 - val_loss: 894.5811\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 843.4821 - val_loss: 868.3339\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 818.8898 - val_loss: 839.5530\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 13ms/step - loss: 807.9523 - val_loss: 832.2744\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 799.0660 - val_loss: 783.1429\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 780.6322 - val_loss: 803.8579\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 777.1345 - val_loss: 794.9372\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 752.6290 - val_loss: 748.0682\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 745.0497 - val_loss: 743.6091\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 754.9563 - val_loss: 720.5682\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 733.6526 - val_loss: 726.6870\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 732.3394 - val_loss: 706.5156\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 734.6005 - val_loss: 721.8123\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 728.0200 - val_loss: 781.8577\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 715.3096 - val_loss: 697.8563\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 722.5468 - val_loss: 686.3204\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 723.5007 - val_loss: 699.2201\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 711.7499 - val_loss: 676.1960\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 712.2106 - val_loss: 704.3376\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 711.3434 - val_loss: 683.2204\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 707.0700 - val_loss: 684.5563\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 702.5898 - val_loss: 689.6191\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 696.8759 - val_loss: 660.0001\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 700.1638 - val_loss: 660.5812\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 689.0001 - val_loss: 667.6743\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 690.8148 - val_loss: 661.4448\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 690.5224 - val_loss: 715.2446\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 705.7585 - val_loss: 675.7196\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 685.2456 - val_loss: 662.4589\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 689.7741 - val_loss: 639.1331\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 684.6335 - val_loss: 644.8466\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 686.5642 - val_loss: 671.8608\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 681.6215 - val_loss: 668.8754\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 666.9406 - val_loss: 662.2589\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 683.1141 - val_loss: 692.4240\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 675.9612 - val_loss: 646.7138\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 677.8877 - val_loss: 635.6380\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 663.9906 - val_loss: 650.0491\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 681.4759 - val_loss: 659.8087\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 670.9980 - val_loss: 633.3046\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 672.4605 - val_loss: 640.9222\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 677.2146 - val_loss: 649.4705\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 2s 12ms/step - loss: 668.9633 - val_loss: 653.1192\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 669.1168 - val_loss: 677.4670\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 665.2815 - val_loss: 628.6733\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 662.2752 - val_loss: 684.8180\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 666.1213 - val_loss: 685.0236\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 667.8795 - val_loss: 661.8520\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 676.6363 - val_loss: 626.3202\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 2s 11ms/step - loss: 670.5538 - val_loss: 654.9401\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 670.1364 - val_loss: 654.7503\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 669.0353 - val_loss: 723.3821\n",
      "59/59 [==============================] - 1s 5ms/step\n",
      "RMSE: 27.08132748785223\n"
     ]
    }
   ],
   "source": [
    "location_coordinates = {'Germany': (51.1638175, 10.4478313), 'United States': (39.7837304, -100.445882),\n",
    "                        'United Kingdom': (54.7023545, -3.2765753), 'Canada': (61.0666922, -107.991707),\n",
    "                        'Spain': (39.3260685, -4.8379791), 'Ireland': (52.865196, -7.9794599),\n",
    "                        'South Africa': (-28.8166236, 24.991639), 'Poland': (52.215933, 19.134422),\n",
    "                        'France': (46.603354, 1.8883335), 'Netherlands': (52.2434979, 5.6343227),\n",
    "                        'Luxembourg': (49.6112768, 6.129799), 'Lithuania': (55.3500003, 23.7499997),\n",
    "                        'Portugal': (39.6621648, -8.1353519), 'Gibraltar': (36.1285933, -5.3474761),\n",
    "                        'Australia': (-24.7761086, 134.755), 'Colombia': (4.099917, -72.9088133),\n",
    "                        'Ukraine': (49.4871968, 31.2718321), 'Slovenia': (46.1199444, 14.8153333),\n",
    "                        'Romania': (45.9852129, 24.6859225), 'Greece': (43.2097838, -77.6930602),\n",
    "                        'India': (22.3511148, 78.6677428), 'Latvia': (56.8406494, 24.7537645),\n",
    "                        'Mauritius': (-20.2759451, 57.5703566), 'Russia': (64.6863136, 97.7453061),\n",
    "                        'Italy': (42.6384261, 12.674297), 'South Korea': (36.638392, 127.6961188),\n",
    "                        'Estonia': (58.7523778, 25.3319078), 'Czech Republic': (49.7439047, 15.3381061),\n",
    "                        'Brazil': (-10.3333333, -53.2), 'Qatar': (25.3336984, 51.2295295),\n",
    "                        'Kenya': (1.4419683, 38.4313975), 'Denmark': (55.670249, 10.3333283),\n",
    "                        'Ghana': (8.0300284, -1.0800271), 'Sweden': (59.6749712, 14.5208584),\n",
    "                        'Turkey': (38.9597594, 34.9249653), 'Switzerland': (46.7985624, 8.2319736),\n",
    "                        'Andorra': (42.5407167, 1.5732033), 'Ecuador': (-1.3397668, -79.3666965),\n",
    "                        'Mexico': (19.4326296, -99.1331785), 'Israel': (30.8124247, 34.8594762),\n",
    "                        'Nigeria': (9.6000359, 7.9999721), 'Saudi Arabia': (25.6242618, 42.3528328),\n",
    "                        'Argentina': (-34.9964963, -64.9672817), 'Japan': (36.5748441, 139.2394179),\n",
    "                        'Central African Republic': (7.0323598, 19.9981227), 'Finland': (63.2467777, 25.9209164),\n",
    "                        'Singapore': (1.357107, 103.8194992), 'Croatia': (45.3658443, 15.6575209),\n",
    "                        'Armenia': (4.491976149999999, -75.74135085294314),\n",
    "                        'Bosnia and Herzegovina': (44.3053476, 17.5961467), 'Pakistan': (30.3308401, 71.247499),\n",
    "                        'Iran': (32.6475314, 54.5643516), 'Bahamas': (24.7736546, -78.0000547),\n",
    "                        'Austria': (47.59397, 14.12456), 'Puerto Rico': (18.2247706, -66.4858295),\n",
    "                        'American Samoa': (-14.297124, -170.7131481), 'Thailand': (13.03876215, 101.70017611907599),\n",
    "                        'Philippines': (12.7503486, 122.7312101), 'Belgium': (50.6402809, 4.6667145),\n",
    "                        'Egypt': (26.2540493, 29.2675469), 'Indonesia': (-2.4833826, 117.8902853),\n",
    "                        'United Arab Emirates': (24.0002488, 53.9994829), 'Malaysia': (4.5693754, 102.2656823),\n",
    "                        'Honduras': (15.2572432, -86.0755145), 'Algeria': (28.0000272, 2.9999825),\n",
    "                        'Iraq': (33.0955793, 44.1749775), 'China': (35.000074, 104.999927),\n",
    "                        'New Zealand': (-41.5000831, 172.8344077), 'Moldova': (47.2879608, 28.5670941),\n",
    "                        'Malta': (35.8885993, 14.4476911), 'Uganda': (1.5333554, 32.2166578),\n",
    "                        'Tunisia': (36.8002068, 10.1857757), 'Peru': (-6.8699697, -75.0458515),\n",
    "                        'Uzbekistan': (41.32373, 63.9528098), 'Georgia': (32.3293809, -83.1137366),\n",
    "                        'Kuwait': (29.3796532, 47.9734174), 'Cyprus': (34.9174159, 32.889902651331866),\n",
    "                        'Costa Rica': (10.2735633, -84.0739102), 'Chile': (-31.7613365, -71.3187697),\n",
    "                        'Bolivia': (-17.0568696, -64.9912286), 'Dominican Republic': (19.0974031, -70.3028026),\n",
    "                        'Vietnam': (15.9266657, 107.9650855), 'Bulgaria': (42.6073975, 25.4856617),\n",
    "                        'Jersey': (49.2214561, -2.1358386), 'Serbia': (44.024322850000004, 21.07657433209902),\n",
    "                        'Hong Kong': (22.350627, 114.1849161)}\n",
    "\n",
    "# Haversine function\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = 6371 * c  # Radius of the Earth in kilometers\n",
    "\n",
    "    return distance\n",
    "\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Calculate distances and add them to the DataFrame\n",
    "df['distance_company_to_residence'] = df.apply(lambda row: haversine(*location_coordinates[row['company_location']], *location_coordinates[row['employee_residence']]), axis=1)\n",
    "\n",
    "# Load your data\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "\n",
    "# Map experience levels to ordinal numbers\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "\n",
    "# Calculate the percentile rank of each salary within its job category\n",
    "df['Percentile'] = df.groupby('job_category')['salary'].rank(pct=True)\n",
    "\n",
    "# Normalize the percentile ranks to a scale of 0 to 1\n",
    "min_percentile = df['Percentile'].min()\n",
    "max_percentile = df['Percentile'].max()\n",
    "df['Normalized_Salary_within_Job_Category'] = (df['Percentile'] - min_percentile) / (max_percentile - min_percentile)\n",
    "\n",
    "# Drop the temporary 'Percentile' column if you don't need it anymore\n",
    "df.drop(columns=['Percentile'], inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to include timestep dimension\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define LSTM model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "lstm_layer = LSTM(128, return_sequences=True)(input_layer)\n",
    "dropout_layer = Dropout(0.2)(lstm_layer)\n",
    "lstm_layer2 = LSTM(64)(dropout_layer)\n",
    "output_layer = Dense(1, activation='linear')(lstm_layer2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4821ba084594397",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Normalized Salary within Job Category\n",
    "RMSE: 25.531453514062534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cce1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9096739711384286\n",
      "Precision: 0.9313276651406148\n",
      "Recall: 0.956989247311828\n",
      "RMSE: 27.08132748785223\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "predictions_scaled = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predictions = predictions_scaled.flatten()\n",
    "\n",
    "# Define thresholds for classification\n",
    "threshold_positive = 100  # Define a suitable threshold based on your problem\n",
    "\n",
    "# Classify predictions into two categories based on the threshold\n",
    "y_test_class = (y_test >= threshold_positive)\n",
    "predictions_class = (predictions >= threshold_positive)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_class, predictions_class)\n",
    "\n",
    "# Calculate percentages\n",
    "total = np.sum(conf_matrix)\n",
    "percentages = (conf_matrix / total) * 100\n",
    "\n",
    "# Define labels for each cell with amount, percentage, and the type of classification\n",
    "labels = np.empty_like(conf_matrix, dtype=object)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        if i == 0 and j == 0:  # True Negative\n",
    "            labels[i, j] = f\"TN\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        elif i == 0 and j == 1:  # False Positive\n",
    "            labels[i, j] = f\"FP\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        elif i == 1 and j == 0:  # False Negative\n",
    "            labels[i, j] = f\"FN\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "        else:  # True Positive\n",
    "            labels[i, j] = f\"TP\\n{conf_matrix[i, j]} ({percentages[i, j]:.2f}%)\"\n",
    "\n",
    "# Plot confusion matrix with labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test_class, predictions_class)\n",
    "precision = precision_score(y_test_class, predictions_class)\n",
    "recall = recall_score(y_test_class, predictions_class)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Calculate and print RMSE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

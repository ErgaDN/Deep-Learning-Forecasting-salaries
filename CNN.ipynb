{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 2s 8ms/step - loss: 26.1646 - mse: 26.1646 - val_loss: 8.4619 - val_mse: 8.4619\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 12.8970 - mse: 12.8970 - val_loss: 10.7619 - val_mse: 10.7619\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 12.4062 - mse: 12.4062 - val_loss: 7.8137 - val_mse: 7.8137\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 11.9907 - mse: 11.9907 - val_loss: 7.8607 - val_mse: 7.8607\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 12.0113 - mse: 12.0113 - val_loss: 7.7849 - val_mse: 7.7849\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 11.5079 - mse: 11.5079 - val_loss: 8.4796 - val_mse: 8.4796\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 11.9898 - mse: 11.9898 - val_loss: 6.8119 - val_mse: 6.8119\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 11.6454 - mse: 11.6454 - val_loss: 16.0286 - val_mse: 16.0286\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 11.6803 - mse: 11.6803 - val_loss: 6.6069 - val_mse: 6.6069\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.4261 - mse: 10.4261 - val_loss: 7.2837 - val_mse: 7.2837\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.5990 - mse: 10.5990 - val_loss: 6.8884 - val_mse: 6.8884\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 10.3002 - mse: 10.3002 - val_loss: 7.8569 - val_mse: 7.8569\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 10.4666 - mse: 10.4666 - val_loss: 6.1458 - val_mse: 6.1458\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 10.3221 - mse: 10.3221 - val_loss: 7.1701 - val_mse: 7.1701\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.7690 - mse: 9.7690 - val_loss: 6.7252 - val_mse: 6.7252\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 10.0245 - mse: 10.0245 - val_loss: 6.5422 - val_mse: 6.5422\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.7295 - mse: 9.7295 - val_loss: 6.6346 - val_mse: 6.6346\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 9.3129 - mse: 9.3129 - val_loss: 6.2687 - val_mse: 6.2687\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.5323 - mse: 9.5323 - val_loss: 9.7661 - val_mse: 9.7661\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 9.4309 - mse: 9.4309 - val_loss: 7.5578 - val_mse: 7.5578\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.0218 - mse: 9.0218 - val_loss: 6.6025 - val_mse: 6.6025\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.9995 - mse: 8.9995 - val_loss: 6.3163 - val_mse: 6.3163\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 9.1620 - mse: 9.1620 - val_loss: 7.7900 - val_mse: 7.7900\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.9620 - mse: 8.9620 - val_loss: 6.2757 - val_mse: 6.2757\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.5918 - mse: 8.5918 - val_loss: 7.3640 - val_mse: 7.3640\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.6307 - mse: 8.6307 - val_loss: 6.3804 - val_mse: 6.3804\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.4805 - mse: 8.4805 - val_loss: 6.7790 - val_mse: 6.7790\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.4391 - mse: 8.4391 - val_loss: 8.0642 - val_mse: 8.0642\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.4227 - mse: 8.4227 - val_loss: 7.0300 - val_mse: 7.0300\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 8.4755 - mse: 8.4755 - val_loss: 6.4082 - val_mse: 6.4082\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.4129 - mse: 8.4129 - val_loss: 6.1695 - val_mse: 6.1695\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.1244 - mse: 8.1244 - val_loss: 6.6316 - val_mse: 6.6316\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.1962 - mse: 8.1962 - val_loss: 6.3129 - val_mse: 6.3129\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.1774 - mse: 8.1774 - val_loss: 8.1040 - val_mse: 8.1040\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3582 - mse: 8.3582 - val_loss: 6.1789 - val_mse: 6.1789\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.0119 - mse: 8.0119 - val_loss: 8.1605 - val_mse: 8.1605\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9166 - mse: 7.9166 - val_loss: 6.3043 - val_mse: 6.3043\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 8.0984 - mse: 8.0984 - val_loss: 6.6585 - val_mse: 6.6585\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.8790 - mse: 7.8790 - val_loss: 7.0476 - val_mse: 7.0476\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.1691 - mse: 8.1691 - val_loss: 6.4655 - val_mse: 6.4655\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9468 - mse: 7.9468 - val_loss: 6.8999 - val_mse: 6.8999\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9256 - mse: 7.9256 - val_loss: 6.6360 - val_mse: 6.6360\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9713 - mse: 7.9713 - val_loss: 9.7319 - val_mse: 9.7319\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 8.3556 - mse: 8.3556 - val_loss: 6.3312 - val_mse: 6.3312\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9221 - mse: 7.9221 - val_loss: 6.0338 - val_mse: 6.0338\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.6198 - mse: 7.6198 - val_loss: 6.3591 - val_mse: 6.3591\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.6367 - mse: 7.6367 - val_loss: 6.4917 - val_mse: 6.4917\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.6535 - mse: 7.6535 - val_loss: 7.3213 - val_mse: 7.3213\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9626 - mse: 7.9626 - val_loss: 6.1693 - val_mse: 6.1693\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7312 - mse: 7.7312 - val_loss: 6.2217 - val_mse: 6.2217\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5732 - mse: 7.5732 - val_loss: 6.1614 - val_mse: 6.1614\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7796 - mse: 7.7796 - val_loss: 6.5005 - val_mse: 6.5005\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 7.8685 - mse: 7.8685 - val_loss: 6.4245 - val_mse: 6.4245\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.8510 - mse: 7.8510 - val_loss: 6.1787 - val_mse: 6.1787\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7382 - mse: 7.7382 - val_loss: 7.2200 - val_mse: 7.2200\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.8266 - mse: 7.8266 - val_loss: 6.8553 - val_mse: 6.8553\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3642 - mse: 7.3642 - val_loss: 6.6190 - val_mse: 6.6190\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.6758 - mse: 7.6758 - val_loss: 6.2699 - val_mse: 6.2699\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.7778 - mse: 7.7778 - val_loss: 6.9931 - val_mse: 6.9931\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 7.9023 - mse: 7.9023 - val_loss: 7.1323 - val_mse: 7.1323\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 8.6567 - mse: 8.6567 - val_loss: 6.9335 - val_mse: 6.9335\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.9265 - mse: 7.9265 - val_loss: 6.1521 - val_mse: 6.1521\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.5419 - mse: 7.5419 - val_loss: 5.9720 - val_mse: 5.9720\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5167 - mse: 7.5167 - val_loss: 6.4648 - val_mse: 6.4648\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5404 - mse: 7.5404 - val_loss: 6.5298 - val_mse: 6.5298\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.8561 - mse: 7.8561 - val_loss: 6.5045 - val_mse: 6.5045\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5572 - mse: 7.5572 - val_loss: 6.3968 - val_mse: 6.3968\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.3151 - mse: 7.3151 - val_loss: 5.9046 - val_mse: 5.9046\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3092 - mse: 7.3092 - val_loss: 5.9514 - val_mse: 5.9514\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5895 - mse: 7.5895 - val_loss: 6.1794 - val_mse: 6.1794\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5237 - mse: 7.5237 - val_loss: 6.8016 - val_mse: 6.8016\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4776 - mse: 7.4776 - val_loss: 6.2374 - val_mse: 6.2374\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.6248 - mse: 7.6248 - val_loss: 6.8371 - val_mse: 6.8371\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4455 - mse: 7.4455 - val_loss: 6.4270 - val_mse: 6.4270\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5726 - mse: 7.5726 - val_loss: 6.3790 - val_mse: 6.3790\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5380 - mse: 7.5380 - val_loss: 5.9425 - val_mse: 5.9425\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4146 - mse: 7.4146 - val_loss: 5.9959 - val_mse: 5.9959\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.2872 - mse: 7.2872 - val_loss: 6.0603 - val_mse: 6.0603\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5949 - mse: 7.5949 - val_loss: 6.0457 - val_mse: 6.0457\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4471 - mse: 7.4471 - val_loss: 6.6065 - val_mse: 6.6065\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.2378 - mse: 7.2378 - val_loss: 6.2297 - val_mse: 6.2297\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.5042 - mse: 7.5042 - val_loss: 6.0271 - val_mse: 6.0271\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.6073 - mse: 7.6073 - val_loss: 5.9303 - val_mse: 5.9303\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.4669 - mse: 7.4669 - val_loss: 6.0167 - val_mse: 6.0167\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.6657 - mse: 7.6657 - val_loss: 6.1446 - val_mse: 6.1446\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.3057 - mse: 7.3057 - val_loss: 6.6997 - val_mse: 6.6997\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3592 - mse: 7.3592 - val_loss: 6.0003 - val_mse: 6.0003\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.6930 - mse: 7.6930 - val_loss: 6.7787 - val_mse: 6.7787\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.5778 - mse: 7.5778 - val_loss: 6.0818 - val_mse: 6.0818\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.3768 - mse: 7.3768 - val_loss: 6.5467 - val_mse: 6.5467\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3883 - mse: 7.3883 - val_loss: 6.1410 - val_mse: 6.1410\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 0s 5ms/step - loss: 7.6629 - mse: 7.6629 - val_loss: 6.1264 - val_mse: 6.1264\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 7.3195 - mse: 7.3195 - val_loss: 6.1120 - val_mse: 6.1120\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4966 - mse: 7.4966 - val_loss: 6.0253 - val_mse: 6.0253\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4398 - mse: 7.4398 - val_loss: 5.9461 - val_mse: 5.9461\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3320 - mse: 7.3320 - val_loss: 5.9424 - val_mse: 5.9424\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.4911 - mse: 7.4911 - val_loss: 5.8982 - val_mse: 5.8982\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3752 - mse: 7.3752 - val_loss: 6.3725 - val_mse: 6.3725\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.3431 - mse: 7.3431 - val_loss: 6.1499 - val_mse: 6.1499\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 7.1554 - mse: 7.1554 - val_loss: 7.0850 - val_mse: 7.0850\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "RMSE: 2.7344692298437923\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 10000\n",
    "\n",
    "# Feature 1: Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "# Feature 2: Map experience levels to ordinal numbers\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Feature 3: Calculate the percentile rank of each salary within its job category\n",
    "df['Percentile'] = df.groupby('job_category')['salary'].rank(pct=True)\n",
    "\n",
    "# Normalize the percentile ranks to a scale of 0 to 1\n",
    "min_percentile = df['Percentile'].min()\n",
    "max_percentile = df['Percentile'].max()\n",
    "df['Normalized_Salary_within_Job_Category'] = (df['Percentile'] - min_percentile) / (max_percentile - min_percentile)\n",
    "\n",
    "# Drop the temporary 'Percentile' column if you don't need it anymore\n",
    "df.drop(columns=['Percentile'], inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to fit CNN input shape\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define CNN model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "conv3 = Conv1D(filters=128, kernel_size=1, activation='relu', padding='valid')(pool2)\n",
    "flatten = Flatten()(conv3)\n",
    "dense1 = Dense(128, activation='relu')(flatten)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output_layer = Dense(1, activation='linear')(dropout)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\",np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

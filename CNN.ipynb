{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "106/106 [==============================] - 2s 8ms/step - loss: 5723.8711 - mse: 5723.8711 - val_loss: 983.4284 - val_mse: 983.4284\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1877.8882 - mse: 1877.8882 - val_loss: 847.1564 - val_mse: 847.1564\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1837.5632 - mse: 1837.5632 - val_loss: 867.0402 - val_mse: 867.0402\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1808.4575 - mse: 1808.4575 - val_loss: 1053.6564 - val_mse: 1053.6564\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1884.4790 - mse: 1884.4790 - val_loss: 916.2490 - val_mse: 916.2490\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1799.9740 - mse: 1799.9740 - val_loss: 1065.9265 - val_mse: 1065.9265\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1693.7988 - mse: 1693.7988 - val_loss: 793.3096 - val_mse: 793.3096\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1744.9812 - mse: 1744.9812 - val_loss: 1131.8223 - val_mse: 1131.8223\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1740.8622 - mse: 1740.8622 - val_loss: 786.9843 - val_mse: 786.9843\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1754.5826 - mse: 1754.5826 - val_loss: 1093.6417 - val_mse: 1093.6417\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1684.9109 - mse: 1684.9109 - val_loss: 778.6097 - val_mse: 778.6097\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1650.3677 - mse: 1650.3677 - val_loss: 744.6678 - val_mse: 744.6678\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1699.7908 - mse: 1699.7908 - val_loss: 709.2284 - val_mse: 709.2284\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 1668.2181 - mse: 1668.2181 - val_loss: 1020.9614 - val_mse: 1020.9614\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1716.1312 - mse: 1716.1312 - val_loss: 847.6746 - val_mse: 847.6746\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1656.2614 - mse: 1656.2614 - val_loss: 771.1602 - val_mse: 771.1602\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1624.9393 - mse: 1624.9393 - val_loss: 681.8304 - val_mse: 681.8304\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1666.6473 - mse: 1666.6473 - val_loss: 785.4316 - val_mse: 785.4316\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1643.6074 - mse: 1643.6074 - val_loss: 703.5779 - val_mse: 703.5779\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1600.1917 - mse: 1600.1917 - val_loss: 656.2249 - val_mse: 656.2249\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1538.9315 - mse: 1538.9315 - val_loss: 987.4398 - val_mse: 987.4398\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1580.4998 - mse: 1580.4998 - val_loss: 707.5640 - val_mse: 707.5640\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1611.9977 - mse: 1611.9977 - val_loss: 651.3574 - val_mse: 651.3574\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1642.7317 - mse: 1642.7317 - val_loss: 682.3605 - val_mse: 682.3605\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1492.6676 - mse: 1492.6676 - val_loss: 732.5785 - val_mse: 732.5785\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 1s 9ms/step - loss: 1552.7024 - mse: 1552.7024 - val_loss: 805.4316 - val_mse: 805.4316\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1546.2086 - mse: 1546.2086 - val_loss: 684.2569 - val_mse: 684.2569\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1597.2570 - mse: 1597.2570 - val_loss: 751.1826 - val_mse: 751.1826\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 1s 10ms/step - loss: 1511.8188 - mse: 1511.8188 - val_loss: 680.5348 - val_mse: 680.5348\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1487.7498 - mse: 1487.7498 - val_loss: 622.9223 - val_mse: 622.9223\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1537.9058 - mse: 1537.9058 - val_loss: 727.9207 - val_mse: 727.9207\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1445.5300 - mse: 1445.5300 - val_loss: 836.3844 - val_mse: 836.3844\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 1477.1296 - mse: 1477.1296 - val_loss: 657.5906 - val_mse: 657.5906\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 1395.3745 - mse: 1395.3745 - val_loss: 650.7912 - val_mse: 650.7912\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1422.9709 - mse: 1422.9709 - val_loss: 634.7144 - val_mse: 634.7144\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1444.6097 - mse: 1444.6097 - val_loss: 667.9424 - val_mse: 667.9424\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1454.2318 - mse: 1454.2318 - val_loss: 1112.6605 - val_mse: 1112.6605\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1434.5455 - mse: 1434.5455 - val_loss: 691.2501 - val_mse: 691.2501\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1460.3385 - mse: 1460.3385 - val_loss: 609.9865 - val_mse: 609.9865\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1362.6495 - mse: 1362.6495 - val_loss: 634.4355 - val_mse: 634.4355\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1370.2896 - mse: 1370.2896 - val_loss: 669.6602 - val_mse: 669.6602\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 1411.2726 - mse: 1411.2726 - val_loss: 808.7268 - val_mse: 808.7268\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1349.4805 - mse: 1349.4805 - val_loss: 680.2329 - val_mse: 680.2329\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1404.6255 - mse: 1404.6255 - val_loss: 794.1664 - val_mse: 794.1664\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1378.9672 - mse: 1378.9672 - val_loss: 631.7093 - val_mse: 631.7093\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1401.5300 - mse: 1401.5300 - val_loss: 752.0521 - val_mse: 752.0521\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1384.0234 - mse: 1384.0234 - val_loss: 707.1416 - val_mse: 707.1416\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1344.5333 - mse: 1344.5333 - val_loss: 693.8621 - val_mse: 693.8621\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1354.2979 - mse: 1354.2979 - val_loss: 593.2707 - val_mse: 593.2707\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1395.2312 - mse: 1395.2312 - val_loss: 595.4379 - val_mse: 595.4379\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1348.1436 - mse: 1348.1436 - val_loss: 634.5519 - val_mse: 634.5519\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1286.7963 - mse: 1286.7963 - val_loss: 627.7933 - val_mse: 627.7933\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1356.7694 - mse: 1356.7694 - val_loss: 631.3931 - val_mse: 631.3931\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 1326.9463 - mse: 1326.9463 - val_loss: 632.9890 - val_mse: 632.9890\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1299.8207 - mse: 1299.8207 - val_loss: 863.2816 - val_mse: 863.2816\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1321.4727 - mse: 1321.4727 - val_loss: 613.5864 - val_mse: 613.5864\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1259.6456 - mse: 1259.6456 - val_loss: 620.0235 - val_mse: 620.0235\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1298.8873 - mse: 1298.8873 - val_loss: 695.1967 - val_mse: 695.1967\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1285.4978 - mse: 1285.4978 - val_loss: 615.2763 - val_mse: 615.2763\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1223.8461 - mse: 1223.8461 - val_loss: 616.2844 - val_mse: 616.2844\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1316.3351 - mse: 1316.3351 - val_loss: 604.9078 - val_mse: 604.9078\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1301.3240 - mse: 1301.3240 - val_loss: 665.6752 - val_mse: 665.6752\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1267.0657 - mse: 1267.0657 - val_loss: 857.9465 - val_mse: 857.9465\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1263.3103 - mse: 1263.3103 - val_loss: 659.9238 - val_mse: 659.9238\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1279.3286 - mse: 1279.3286 - val_loss: 860.8391 - val_mse: 860.8391\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1258.1011 - mse: 1258.1011 - val_loss: 648.2528 - val_mse: 648.2528\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1258.8367 - mse: 1258.8367 - val_loss: 736.2671 - val_mse: 736.2671\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1233.0060 - mse: 1233.0060 - val_loss: 749.1623 - val_mse: 749.1623\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1232.1082 - mse: 1232.1082 - val_loss: 761.3499 - val_mse: 761.3499\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1296.9247 - mse: 1296.9247 - val_loss: 683.7426 - val_mse: 683.7426\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1235.6974 - mse: 1235.6974 - val_loss: 649.6694 - val_mse: 649.6694\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1265.5303 - mse: 1265.5303 - val_loss: 621.0646 - val_mse: 621.0646\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1280.9404 - mse: 1280.9404 - val_loss: 741.2188 - val_mse: 741.2188\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1251.4187 - mse: 1251.4187 - val_loss: 596.5322 - val_mse: 596.5322\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1229.3466 - mse: 1229.3466 - val_loss: 706.1243 - val_mse: 706.1243\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1213.1506 - mse: 1213.1506 - val_loss: 588.5736 - val_mse: 588.5736\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1215.7809 - mse: 1215.7809 - val_loss: 812.7638 - val_mse: 812.7638\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1189.6261 - mse: 1189.6261 - val_loss: 608.6725 - val_mse: 608.6725\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1235.6272 - mse: 1235.6272 - val_loss: 627.2588 - val_mse: 627.2588\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1232.3575 - mse: 1232.3575 - val_loss: 603.8713 - val_mse: 603.8713\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1244.8606 - mse: 1244.8606 - val_loss: 591.4006 - val_mse: 591.4006\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1156.8915 - mse: 1156.8915 - val_loss: 667.2087 - val_mse: 667.2087\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1184.3179 - mse: 1184.3179 - val_loss: 698.1856 - val_mse: 698.1855\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1123.2007 - mse: 1123.2007 - val_loss: 600.4761 - val_mse: 600.4761\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1161.5139 - mse: 1161.5139 - val_loss: 612.8851 - val_mse: 612.8851\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1095.4889 - mse: 1095.4889 - val_loss: 634.4171 - val_mse: 634.4171\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1170.4005 - mse: 1170.4005 - val_loss: 706.9627 - val_mse: 706.9627\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1141.6342 - mse: 1141.6342 - val_loss: 606.4016 - val_mse: 606.4016\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 1s 5ms/step - loss: 1200.3508 - mse: 1200.3508 - val_loss: 730.1545 - val_mse: 730.1545\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1118.9055 - mse: 1118.9055 - val_loss: 614.1600 - val_mse: 614.1600\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1111.2616 - mse: 1111.2616 - val_loss: 722.2093 - val_mse: 722.2093\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1154.0299 - mse: 1154.0299 - val_loss: 623.8613 - val_mse: 623.8613\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1111.0903 - mse: 1111.0903 - val_loss: 730.1459 - val_mse: 730.1459\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1127.1206 - mse: 1127.1206 - val_loss: 740.6253 - val_mse: 740.6253\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1087.5300 - mse: 1087.5300 - val_loss: 766.2968 - val_mse: 766.2968\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1134.8516 - mse: 1134.8516 - val_loss: 596.1462 - val_mse: 596.1462\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1113.5222 - mse: 1113.5222 - val_loss: 787.3414 - val_mse: 787.3414\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1118.4349 - mse: 1118.4349 - val_loss: 787.3615 - val_mse: 787.3615\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1098.2627 - mse: 1098.2627 - val_loss: 592.8694 - val_mse: 592.8694\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 1s 6ms/step - loss: 1086.3361 - mse: 1086.3361 - val_loss: 612.4498 - val_mse: 612.4498\n",
      "59/59 [==============================] - 0s 3ms/step\n",
      "RMSE: 25.062300750815357\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"jobs_in_data.csv\")\n",
    "\n",
    "# Split the 'salary_in_usd' column by 1000\n",
    "df['salary_in_usd'] /= 1000\n",
    "\n",
    "# Feature 1: Calculate the ratio of \"salary_in_usd\" to \"salary\"\n",
    "df['salary_ratio'] = df['salary_in_usd'] / df['salary']\n",
    "\n",
    "# Feature 2: Map experience levels to ordinal numbers\n",
    "experience_mapping = {\n",
    "    'Entry-level': 1,\n",
    "    'Mid-level': 2,\n",
    "    'Senior': 3,\n",
    "    'Executive': 4\n",
    "}\n",
    "df['experience_level_encoded'] = df['experience_level'].map(experience_mapping)\n",
    "\n",
    "# Feature 3: Calculate the percentile rank of each salary within its job category\n",
    "df['Percentile'] = df.groupby('job_category')['salary'].rank(pct=True)\n",
    "\n",
    "# Normalize the percentile ranks to a scale of 0 to 1\n",
    "min_percentile = df['Percentile'].min()\n",
    "max_percentile = df['Percentile'].max()\n",
    "df['Normalized_Salary_within_Job_Category'] = (df['Percentile'] - min_percentile) / (max_percentile - min_percentile)\n",
    "\n",
    "# Drop the temporary 'Percentile' column if you don't need it anymore\n",
    "df.drop(columns=['Percentile'], inplace=True)\n",
    "\n",
    "# Define features and target variable\n",
    "X_numerical = df.select_dtypes(include=np.number).drop(\n",
    "    columns=[\"salary_in_usd\", \"salary\"])  # Select only numeric columns\n",
    "y = df[\"salary_in_usd\"]\n",
    "\n",
    "# Scale numerical data\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_num, X_test_num, y_train, y_test = train_test_split(X_numerical_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the input data to fit CNN input shape\n",
    "X_train_reshaped = X_train_num.reshape(X_train_num.shape[0], X_train_num.shape[1], 1)\n",
    "X_test_reshaped = X_test_num.reshape(X_test_num.shape[0], X_test_num.shape[1], 1)\n",
    "\n",
    "# Define CNN model\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "conv2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "dense1 = Dense(64, activation='relu')(flatten)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output_layer = Dense(1, activation='linear')(dropout)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step\n",
      "RMSE: 25.062300750815357\n",
      "Accuracy: 84.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"RMSE:\", np.sqrt(mse))\n",
    "\n",
    "# Calculate R-squared (accuracy)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "accuracy = np.round(r2 * 100, 2)\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

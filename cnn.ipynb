{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('jobs_in_data.csv')\n",
    "\n",
    "# Divide the 'salary' column by 1000\n",
    "data['salary'] /= 1000\n",
    "data['salary_in_usd'] /= 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locations = data['company_location'].unique()\n",
    "# Placeholder GDP per capital values for each country (in USD)\n",
    "country_gdp_per_capital = {\n",
    "    'Germany': 52000,\n",
    "    'United States': 65000,\n",
    "    'United Kingdom': 48000,\n",
    "    'Canada': 45000,\n",
    "    'Spain': 38000,\n",
    "    'Ireland': 65000,\n",
    "    'South Africa': 6500,\n",
    "    'Poland': 33000,\n",
    "    'France': 42000,\n",
    "    'Netherlands': 53000,\n",
    "    'Luxembourg': 115000,\n",
    "    'Lithuania': 32000,\n",
    "    'Portugal': 29000,\n",
    "    'Gibraltar': 89000,\n",
    "    'Australia': 54000,\n",
    "    'Colombia': 14800,\n",
    "    'Ukraine': 9500,\n",
    "    'Slovenia': 38000,\n",
    "    'Romania': 13000,\n",
    "    'Greece': 29000,\n",
    "    'India': 2200,\n",
    "    'Latvia': 32000,\n",
    "    'Mauritius': 11000,\n",
    "    'Russia': 11000,\n",
    "    'Italy': 35000,\n",
    "    'South Korea': 42000,\n",
    "    'Estonia': 32000,\n",
    "    'Czech Republic': 38000,\n",
    "    'Brazil': 8900,\n",
    "    'Qatar': 62000,\n",
    "    'Kenya': 1800,\n",
    "    'Denmark': 60000,\n",
    "    'Ghana': 2200,\n",
    "    'Sweden': 54000,\n",
    "    'Turkey': 11000,\n",
    "    'Switzerland': 83000,\n",
    "    'Andorra': 49000,\n",
    "    'Ecuador': 6600,\n",
    "    'Mexico': 9900,\n",
    "    'Israel': 42000,\n",
    "    'Nigeria': 2400,\n",
    "    'Saudi Arabia': 22000,\n",
    "    'Argentina': 11600,\n",
    "    'Japan': 42000,\n",
    "    'Central African Republic': 700,\n",
    "    'Finland': 53000,\n",
    "    'Singapore': 65000,\n",
    "    'Croatia': 27000,\n",
    "    'Armenia': 4400,\n",
    "    'Bosnia and Herzegovina': 11900,\n",
    "    'Pakistan': 1600,\n",
    "    'Iran': 6000,\n",
    "    'Bahamas': 31000,\n",
    "    'Austria': 54000,\n",
    "    'Puerto Rico': 39100,\n",
    "    'American Samoa': 14000,\n",
    "    'Thailand': 7800,\n",
    "    'Philippines': 3500,\n",
    "    'Belgium': 51000,\n",
    "    'Egypt': 3000,\n",
    "    'Indonesia': 4400,\n",
    "    'United Arab Emirates': 43000,\n",
    "    'Malaysia': 13000,\n",
    "    'Honduras': 2500,\n",
    "    'Algeria': 4200,\n",
    "    'Iraq': 5700,\n",
    "    'China': 11000,\n",
    "    'New Zealand': 44000,\n",
    "    'Moldova': 3100,\n",
    "    'Malta': 45000\n",
    "}\n",
    "# Define thresholds for GDP per capita (or any other criterion you choose)\n",
    "high_income_threshold = 40000  # GDP per capita above this value will be considered first world\n",
    "middle_income_threshold = 10000  # GDP per capita between this and high_income_threshold will be considered second world\n",
    "\n",
    "# Create a dictionary to map country names to their corresponding development levels\n",
    "development_levels = {}\n",
    "for country in unique_locations:\n",
    "    # Assign development levels based on GDP per capita\n",
    "    if country in country_gdp_per_capital:\n",
    "        if country_gdp_per_capital[country] > high_income_threshold:\n",
    "            development_levels[country] = 'First World'\n",
    "        elif country_gdp_per_capital[country] > middle_income_threshold:\n",
    "            development_levels[country] = 'Second World'\n",
    "        else:\n",
    "            development_levels[country] = 'Third World'\n",
    "    else:\n",
    "        development_levels[country] = 'Data Not Available'  # Handle missing GDP per capita data\n",
    "\n",
    "# Create a new column 'development_level' based on the assigned levels\n",
    "data['development_level'] = data['company_location'].map(development_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction Terms\n",
    "data['work_year_experience'] = data['work_year'] * data['experience_level']\n",
    "data['work_year_job_category'] = data['work_year'] * data['job_category']\n",
    "data['salary_divide_dolar'] = data['salary_in_usd']/data['salary']\n",
    "\n",
    "# Aggregate Statistics\n",
    "agg_salary_by_job_category = data.groupby('job_category')['salary'].agg(['mean', 'median', 'std']).reset_index()\n",
    "agg_salary_by_job_category.columns = ['job_category', 'avg_salary_job_category', 'median_salary_job_category', 'std_salary_job_category']\n",
    "data = data.merge(agg_salary_by_job_category, on='job_category', how='left')\n",
    "\n",
    "# Temporal Trends (if applicable)\n",
    "agg_salary_by_year = data.groupby('work_year')['salary'].mean().reset_index()\n",
    "agg_salary_by_year.columns = ['work_year', 'avg_salary_year']\n",
    "data = data.merge(agg_salary_by_year, on='work_year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "data['employment_type_encoded'] = label_encoder.fit_transform(data['employment_type'])\n",
    "data['job_title_encoded'] = label_encoder.fit_transform(data['job_title'])\n",
    "\n",
    "# Creating interaction features\n",
    "data['employment_type_job_title'] = data['employment_type_encoded'] * data['job_title_encoded']\n",
    "\n",
    "data['work_setting_encoded'] = label_encoder.fit_transform(data['work_setting'])\n",
    "data['job_category_encoded'] = label_encoder.fit_transform(data['job_category'])\n",
    "\n",
    "# Creating interaction features\n",
    "data['work_setting_job_category'] = data['work_setting_encoded'] * data['job_category_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'salary_in_usd' column since we're ignoring it\n",
    "# data.drop(columns=['salary_in_usd'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['salary', 'salary_in_usd'])\n",
    "y = data['salary_in_usd']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reshape the input data for Conv1D\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(128, 5, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),\n",
    "    MaxPooling1D(5),\n",
    "    Conv1D(64, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test_reshaped, y_test)\n",
    "print('Test Loss:', loss)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_reshaped).flatten()\n",
    "\n",
    "# Visualize Predictions vs. Actual Values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, alpha=0.5)\n",
    "plt.xlabel('Actual Salary')\n",
    "plt.ylabel('Predicted Salary')\n",
    "plt.title('Actual vs. Predicted Salaries')\n",
    "plt.show()\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Define thresholds for classification\n",
    "threshold_positive = 100  # Define a suitable threshold based on your problem\n",
    "\n",
    "# Classify predictions into two categories based on the threshold\n",
    "y_test_class = (y_test >= threshold_positive)\n",
    "predictions_class = (predictions >= threshold_positive)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_class, predictions_class)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test_class, predictions_class)\n",
    "precision = precision_score(y_test_class, predictions_class)\n",
    "recall = recall_score(y_test_class, predictions_class)\n",
    "\n",
    "# Print confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print accuracy, precision, and recall\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error: 39.019920233220354\n",
    "Mean Squared Error: 2638.369287022722\n",
    "Root Mean Squared Error: 51.36505900924014\n",
    "Confusion Matrix:\n",
    "[[ 155  228]\n",
    " [  40 1448]]\n",
    "Accuracy: 0.8567610903260289\n",
    "Precision: 0.863961813842482\n",
    "Recall: 0.9731182795698925"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "    Learning Rate  Dropout Rate  Epochs    Test Loss\n",
      "0          0.0100           0.0      50  2555.965820\n",
      "1          0.0100           0.0     100  2646.629883\n",
      "2          0.0100           0.0     200  2549.389893\n",
      "3          0.0100           0.2      50  2601.021973\n",
      "4          0.0100           0.2     100  2615.562744\n",
      "5          0.0100           0.2     200  2579.971680\n",
      "6          0.0100           0.5      50  2593.843506\n",
      "7          0.0100           0.5     100  2717.121338\n",
      "8          0.0100           0.5     200  2571.627197\n",
      "9          0.0010           0.0      50  2597.697754\n",
      "10         0.0010           0.0     100  2630.652344\n",
      "11         0.0010           0.0     200  2577.537354\n",
      "12         0.0010           0.2      50  2651.308594\n",
      "13         0.0010           0.2     100  2643.282471\n",
      "14         0.0010           0.2     200  2592.799561\n",
      "15         0.0010           0.5      50  2580.681885\n",
      "16         0.0010           0.5     100  2609.062256\n",
      "17         0.0010           0.5     200  2653.062256\n",
      "18         0.0001           0.0      50  2576.301514\n",
      "19         0.0001           0.0     100  2571.071533\n",
      "20         0.0001           0.0     200  2535.180908\n",
      "21         0.0001           0.2      50  2567.072754\n",
      "22         0.0001           0.2     100  2568.615234\n",
      "23         0.0001           0.2     200  2611.394531\n",
      "24         0.0001           0.5      50  2605.258301\n",
      "25         0.0001           0.5     100  2567.711670\n",
      "26         0.0001           0.5     200  2578.318115\n",
      "\n",
      "Best Combination:\n",
      "Learning Rate       0.000100\n",
      "Dropout Rate        0.000000\n",
      "Epochs            200.000000\n",
      "Test Loss        2535.180908\n",
      "Name: 20, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from itertools import product\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('jobs_in_data.csv')\n",
    "\n",
    "# Drop the 'salary_in_usd' column since we're ignoring it\n",
    "data.drop(columns=['salary_in_usd'], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "data = pd.get_dummies(data)\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['salary'])\n",
    "y = data['salary'] / 1000  # Divide the 'salary' column by 1000 here\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "def create_model(learning_rate, dropout):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "dropouts = [0, 0.2, 0.5]\n",
    "epochs = [50, 100, 200]\n",
    "\n",
    "# Perform grid search\n",
    "results = []\n",
    "\n",
    "for lr, dropout_rate, epoch in product(learning_rates, dropouts, epochs):\n",
    "    model = create_model(lr, dropout_rate)\n",
    "    model.fit(X_train_scaled, y_train, epochs=epoch, batch_size=32, verbose=0)\n",
    "    loss = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    results.append((lr, dropout_rate, epoch, loss))\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results, columns=['Learning Rate', 'Dropout Rate', 'Epochs', 'Test Loss'])\n",
    "print(results_df)\n",
    "\n",
    "# Find the combination with the lowest test loss\n",
    "best_combination = results_df.loc[results_df['Test Loss'].idxmin()]\n",
    "print(\"\\nBest Combination:\")\n",
    "print(best_combination)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

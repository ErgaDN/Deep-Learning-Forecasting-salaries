{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a198fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import sklearn.model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow.compat.v1 as tf\n",
    "from xgboost import XGBClassifier\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace551a",
   "metadata": {},
   "source": [
    "defined a file path for a job_data.csv and read it into a pandas DataFrame called df, and printed the first 3 rows of the DataFrame to examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa6752-8a12-4e8a-988e-499c16246559",
   "metadata": {},
   "outputs": [],
   "source": [
    "address = r'jobs_in_data.csv'  # Defining the file path for the CSV file\n",
    "df = pd.read_csv(address)  # Reading the data from CSV file into a DataFrame 'df'\n",
    "\n",
    "df.head(3) # Printing the first 3 rows of the DataFrame to examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b262e",
   "metadata": {},
   "source": [
    " Perform one-hot encoding on categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066aaab9-f1eb-42ca-b977-7d14fec967ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df)\n",
    "df_encoded.head() # Printing the first 5 rows of the DataFrame to examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a98df-0963-4b44-b6dc-4bd5715a9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target variable (y)\n",
    "\n",
    "X = df_encoded.drop(columns=['salary','salary_in_usd'])  # Drop the target column\n",
    "y = df_encoded['salary']  # Target column\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a linear regression model\n",
    "basic_model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "basic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing set\n",
    "y_pred = basic_model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"root mse\",math.sqrt(mse) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990202e",
   "metadata": {},
   "source": [
    "The Mean Squared Error after one-hot encoding is 2.7860732177114695e+33.\n",
    "Now we will try to improve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f9207a",
   "metadata": {},
   "source": [
    "Assigning development levels to countries based on GDP per capita thresholds and performing one-hot encoding to create additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafa745",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salary_usd_test = y_test.mean()\n",
    "print(\"Average Salary in USD (Test Set):\", average_salary_usd_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f236a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the average salary in USD for every sample in the test set\n",
    "y_pred_average = np.full_like(y_test, average_salary_usd_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse_average = mean_squared_error(y_test, y_pred_average)\n",
    "print(\"Mean Squared Error (Predicting Average Salary in USD):\", mse_average)\n",
    "print(\"root mse\",math.sqrt(mse_average) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f14894-8ac8-4ba7-a5f1-af167d1e8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locations = df['company_location'].unique()\n",
    "\n",
    "# Printing all unique options in the 'company_location' column\n",
    "# for location in unique_locations:\n",
    "#     print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10053651-b50f-43e6-924d-b24471008b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder GDP per capita values for each country (in USD)\n",
    "country_gdp_per_capita = {\n",
    "    'Germany': 52000,\n",
    "    'United States': 65000,\n",
    "    'United Kingdom': 48000,\n",
    "    'Canada': 45000,\n",
    "    'Spain': 38000,\n",
    "    'Ireland': 65000,\n",
    "    'South Africa': 6500,\n",
    "    'Poland': 33000,\n",
    "    'France': 42000,\n",
    "    'Netherlands': 53000,\n",
    "    'Luxembourg': 115000,\n",
    "    'Lithuania': 32000,\n",
    "    'Portugal': 29000,\n",
    "    'Gibraltar': 89000,\n",
    "    'Australia': 54000,\n",
    "    'Colombia': 14800,\n",
    "    'Ukraine': 9500,\n",
    "    'Slovenia': 38000,\n",
    "    'Romania': 13000,\n",
    "    'Greece': 29000,\n",
    "    'India': 2200,\n",
    "    'Latvia': 32000,\n",
    "    'Mauritius': 11000,\n",
    "    'Russia': 11000,\n",
    "    'Italy': 35000,\n",
    "    'South Korea': 42000,\n",
    "    'Estonia': 32000,\n",
    "    'Czech Republic': 38000,\n",
    "    'Brazil': 8900,\n",
    "    'Qatar': 62000,\n",
    "    'Kenya': 1800,\n",
    "    'Denmark': 60000,\n",
    "    'Ghana': 2200,\n",
    "    'Sweden': 54000,\n",
    "    'Turkey': 11000,\n",
    "    'Switzerland': 83000,\n",
    "    'Andorra': 49000,\n",
    "    'Ecuador': 6600,\n",
    "    'Mexico': 9900,\n",
    "    'Israel': 42000,\n",
    "    'Nigeria': 2400,\n",
    "    'Saudi Arabia': 22000,\n",
    "    'Argentina': 11600,\n",
    "    'Japan': 42000,\n",
    "    'Central African Republic': 700,\n",
    "    'Finland': 53000,\n",
    "    'Singapore': 65000,\n",
    "    'Croatia': 27000,\n",
    "    'Armenia': 4400,\n",
    "    'Bosnia and Herzegovina': 11900,\n",
    "    'Pakistan': 1600,\n",
    "    'Iran': 6000,\n",
    "    'Bahamas': 31000,\n",
    "    'Austria': 54000,\n",
    "    'Puerto Rico': 39100,\n",
    "    'American Samoa': 14000,\n",
    "    'Thailand': 7800,\n",
    "    'Philippines': 3500,\n",
    "    'Belgium': 51000,\n",
    "    'Egypt': 3000,\n",
    "    'Indonesia': 4400,\n",
    "    'United Arab Emirates': 43000,\n",
    "    'Malaysia': 13000,\n",
    "    'Honduras': 2500,\n",
    "    'Algeria': 4200,\n",
    "    'Iraq': 5700,\n",
    "    'China': 11000,\n",
    "    'New Zealand': 44000,\n",
    "    'Moldova': 3100,\n",
    "    'Malta': 45000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0de78-26e5-4f98-81ba-69d005022232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for GDP per capita (or any other criterion you choose)\n",
    "high_income_threshold = 40000  # GDP per capita above this value will be considered first world\n",
    "middle_income_threshold = 10000  # GDP per capita between this and high_income_threshold will be considered second world\n",
    "\n",
    "# Create a dictionary to map country names to their corresponding development levels\n",
    "development_levels = {}\n",
    "for country in unique_locations:\n",
    "    # Assign development levels based on GDP per capita\n",
    "    if country in country_gdp_per_capita:\n",
    "        if country_gdp_per_capita[country] > high_income_threshold:\n",
    "            development_levels[country] = 'First World'\n",
    "        elif country_gdp_per_capita[country] > middle_income_threshold:\n",
    "            development_levels[country] = 'Second World'\n",
    "        else:\n",
    "            development_levels[country] = 'Third World'\n",
    "    else:\n",
    "        development_levels[country] = 'Data Not Available'  # Handle missing GDP per capita data\n",
    "\n",
    "# Create a new column 'development_level' based on the assigned levels\n",
    "df['development_level'] = df['company_location'].map(development_levels)\n",
    "\n",
    "# Perform one-hot encoding on the 'development_level' column\n",
    "df_encoded = pd.get_dummies(df, columns=['development_level'])\n",
    "\n",
    "# Perform one-hot encoding on all categorical columns\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc13b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop(columns=['salary','salary_in_usd'])  # Drop the target column\n",
    "y = df_encoded['salary']  # Target column\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a linear regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72714dfe",
   "metadata": {},
   "source": [
    "The Mean Squared Error after add GDP feature is 1.044927689722729e+33.\n",
    "\n",
    "Reducing the mean squared error (MSE) from 2.7860732177114695e+33 to 1.044927689722729e+33 indicates an improvement in the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b38dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction Terms\n",
    "df['work_year_experience'] = df['work_year'] * df['experience_level']\n",
    "df['work_year_job_category'] = df['work_year'] * df['job_category']\n",
    "df['salary_divide_dolar'] = df['salary_in_usd']/df['salary']\n",
    "\n",
    "# Aggregate Statistics\n",
    "agg_salary_by_job_category = df.groupby('job_category')['salary'].agg(['mean', 'median', 'std']).reset_index()\n",
    "agg_salary_by_job_category.columns = ['job_category', 'avg_salary_job_category', 'median_salary_job_category', 'std_salary_job_category']\n",
    "df = df.merge(agg_salary_by_job_category, on='job_category', how='left')\n",
    "\n",
    "# Temporal Trends (if applicable)\n",
    "# Example: You can calculate the average salary trend over the years\n",
    "agg_salary_by_year = df.groupby('work_year')['salary'].mean().reset_index()\n",
    "agg_salary_by_year.columns = ['work_year', 'avg_salary_year']\n",
    "df = df.merge(agg_salary_by_year, on='work_year', how='left')\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop(columns=['salary','salary_in_usd'])  # Drop the target column\n",
    "y = df_encoded['salary']  # Target column\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a linear regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Improved Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['employment_type_encoded'] = label_encoder.fit_transform(df['employment_type'])\n",
    "df['job_title_encoded'] = label_encoder.fit_transform(df['job_title'])\n",
    "\n",
    "# Creating interaction features\n",
    "df['employment_type_job_title'] = df['employment_type_encoded'] * df['job_title_encoded']\n",
    "\n",
    "# Perform one-hot encoding on the updated DataFrame\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop(columns=['salary', 'salary_in_usd'])  \n",
    "y = df_encoded['salary']  \n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error after feature engineering:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['work_setting_encoded'] = label_encoder.fit_transform(df['work_setting'])\n",
    "df['job_category_encoded'] = label_encoder.fit_transform(df['job_category'])\n",
    "\n",
    "# Creating interaction features\n",
    "df['work_setting_job_category'] = df['work_setting_encoded'] * df['job_category_encoded']\n",
    "\n",
    "# Perform one-hot encoding on the updated DataFrame\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = df_encoded.drop(columns=['salary', 'salary_in_usd'])  \n",
    "y = df_encoded['salary']  \n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a linear regression model\n",
    "# model = LinearRegression()\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculating the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error after feature engineering:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # Alpha is the regularization strength\n",
    "\n",
    "# Fit the model to the training data\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error for Ridge Regression\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"Mean Squared Error (Ridge Regression):\", mse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d52c3c",
   "metadata": {},
   "source": [
    "Mean Squared Error (Ridge Regression): 2602098554.267593\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust hyperparameters such as n_estimators\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error for Random Forest Regressor\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error (Random Forest):\", mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89346a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the XGBoost model\n",
    "import math\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)  # You can adjust hyperparameters\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error for XGBoost\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(\"Mean Squared Error (XGBoost):\", mse_xgb)\n",
    "print(\"root MSE\", math.sqrt(mse_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80975c36",
   "metadata": {},
   "source": [
    "Mean Squared Error (XGBoost): 2540649430.884165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f951146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
